---
title: Gregorova et al. (2023)
subtitle: 'Access to meaning from visual input: Object and word frequency effects in categorization behavior'
date: 2023/10/01
authors:
- Gregorová, Klara
- Turini, Jacopo
- Gagl, Benjamin
- Võ, Melissa Le-Hoa
journal: J. Exp. Psychol. Gen.
paper_url: https://doi.org/10.1037/xge0001342
data_url: https://osf.io/d3j9h
tags:
- 
---

Object and word recognition are both cognitive processes that transform visual input into meaning. When reading words, the frequency of their occurrence ("word frequency," WF) strongly modulates access to their meaning, as seen in recognition performance. Does the frequency of objects in our world also affect access to their meaning? With object labels available in real-world image datasets, one can now estimate the frequency of occurrence of objects in scenes ("object frequency," OF). We explored frequency effects in word and object recognition behavior by employing a natural versus man-made categorization task (Experiment 1) and a matching-mismatching priming task (Experiments 2-3). In Experiment 1, we found a WF effect for both words and objects but no OF effect. In Experiment 2, we replicated the WF effect for both stimulus types during cross-modal priming but not uni-modal priming. Moreover, in cross-modal priming, we found an OF effect for both objects and words, but with faster responses when objects occur less frequently in image datasets. We replicated this counterintuitive OF effect in Experiment 3 and suggest that better recognition of rare objects might interact with the structure of object categories: while access to the meaning of objects and words is faster when their meaning often occurs in our language, the homogeneity of object categories seems to also impact recognition, mainly when semantic processing happens in the context of previously presented information. These findings have major implications for studies attempting to include frequency measures in investigations of access to meaning from visual inputs. (PsycInfo Database Record (c) 2023 APA, all rights reserved).
