<!DOCTYPE html><html lang="zh-CN"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta name="author" content="DSST/NIMH"><title>OpenData</title><meta name="description" content="A collection of publicly available&lt;br&gt;behavioral datasets"><meta name="keywords"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="renderer" content="webkit"><link rel="shortcut icon" type="image/x-icon" href="/images/favicon.webp"><link rel="stylesheet" href="/opendata/css/style.css"><link rel="stylesheet" href="/opendata/css/blog_basic.css"><link rel="stylesheet" href="/opendata/css/font-awesome.min.css"><link rel="stylesheet" href="/opendata/css/insight.css"><link rel="stylesheet" href="/opendata/css/search.css"><link rel="alternate" type="application/atom+xml" title="ATOM 1.0" href="/atom.xml"><script src="/opendata/js/jquery.js"></script><!-- Global site tag (gtag.js) - Google Analytics--><script async src="https://www.googletagmanager.com/gtag/js?id=G-PTJE4Z001J"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-PTJE4Z001J');</script><meta name="generator" content="Hexo 6.3.0"></head><body><div class="page-top animated fadeInDown"><div class="nav"><li><a href="/opendata">Home</a></li><li><a href="/opendata/archives">Archives</a></li><li><a href="/opendata/tags">Tags</a></li><li><a href="/opendata/about">About</a></li><li><a href="/opendata/contribute">Contribute</a></li></div><div class="information"><div class="nav_right_btn"><li><a class="fa fa-chevron-left" onclick="window.history.go(-1)" style="display:none;"></a></li><li><a class="fa fa-search" onclick="openWindow();"></a></li></div><div class="avatar"><img src="/opendata/images/logo.webp" alt="favicon"></div></div></div><div class="sidebar animated fadeInDown"><div class="sidebar-top"><div class="logo-title"><div class="title"><img src="/opendata/images/logo.webp" style="width:175px;" alt="favicon"><h3 title=""><a href="/opendata">OpenData</a></h3><div class="description"><p>A collection of publicly available<br>behavioral datasets</p></div></div><ul class="social-links"><li><a target="_blank" rel="noopener" href="https://github.com/nimh-dsst/opendata"><i class="fa fa-github"></i></a></li></ul></div></div><div class="footer"><div class="p"> <span> MIT License </span><i class="fa fa-star"></i><span> DSST/NIMH</span></div><div class="by_farbox"><span>Powered by </span><a href="https://hexo.io/zh-cn/" target="_blank">Hexo </a><span> & </span><span>Anatolo </span></div><div class="beian"></div></div></div><div class="main"><div class="autopagerize_page_element"><div class="content"><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/blackwell-et-al-2023/">Blackwell et al. (2023)</a></h3></div><div class="post-subtitle"><h4>Measuring symptom-specific panic-relevant associations using single-target implicit association tests</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.31234/osf.io/2tjym">[Paper] </a><a target="_blank" rel="noopener" href="https://osf.io/x48uh/"> [Data]</a></div><div class="post-content"><p>According to major cognitive accounts of panic disorder, bodily sensations can lead to automatic activation of an associative fear network, potentially triggering a cascade of cognitive, emotional, and physiological responses culminating in a panic attack. However, the evidence for the automatic associations assumed by these models is mixed. This may reflect the heterogeneous nature of panic disorder, in that the relative importance of different bodily sensations and symptoms varies between individuals. The current study aimed to test this possibility via measuring the...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/viviani-et-al-2023/">Viviani et al. (2023)</a></h3></div><div class="post-subtitle"><h4>A comparison between different variants of the spatial Stroop task: The influence of analytic flexibility on Stroop effect estimates and reliability</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.3758/s13428-023-02091-8">[Paper] </a><a href="/opendata/osf.io/5sm9j/"> [Data]</a></div><div class="post-content"><p>The spatial Stroop task measures the ability to resolve interference between relevant and irrelevant spatial information. We recently proposed a four-choice spatial Stroop task that ensures methodological advantages over the original color-word verbal Stroop task, requiring participants to indicate the direction of an arrow while ignoring its position in one of the screen corners. However, its peripheral spatial arrangement might represent a methodological weakness and could introduce experimental confounds. Thus, aiming at improving our “Peripheral” spatial Stroop, we...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/fornari-et-al-2023/">Fornari et al. (2023)</a></h3></div><div class="post-subtitle"><h4>Neuro-computational mechanisms and individual biases in action-outcome learning under moral conflict</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1038/s41467-023-36807-3">[Paper] </a><a target="_blank" rel="noopener" href="https://doi.org/10.17605/OSF.IO/RK8W4"> [Data]</a></div><div class="post-content"><p>Learning to predict action outcomes in morally conflicting situations is essential for social decision-making but poorly understood. Here we tested which forms of Reinforcement Learning Theory capture how participants learn to choose between self-money and other-shocks, and how they adapt to changes in contingencies. We find choices were better described by a reinforcement learning model based on the current value of separately expected outcomes than by one based on the combined historical values of past outcomes. Participants track expected values of self-money and...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/souza-frischkorn-2023/">Souza &amp; Frischkorn (2023)</a></h3></div><div class="post-subtitle"><h4>A diffusion model analysis of age and individual differences in the retro-cue benefit</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.31234/osf.io/utgvj">[Paper] </a><a target="_blank" rel="noopener" href="https://osf.io/sfycz/?view_only=773072ff91d34460a04f4b1375bd4472"> [Data]</a></div><div class="post-content"><p>The limited capacity of working memory constrains how well we can think and act. Focused attention alleviates this limitation by prioritizing the most relevant mental content at a given time. Retro-cues tap into this ability by guiding attention to one working memory content, thereby improving memory speed and accuracy. So far, few attempts have been made to understand the retro-cue effect through well-established computational models, nor how their parameters track age-related changes and individual differences in focusing efficiency. The present study aims to close...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/prieto-et-al-2023/">Prieto et al. (2023)</a></h3></div><div class="post-subtitle"><h4>Metacognition modulates the relation between maternal severity of psychopathological symptoms and reported child symptoms</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.31234/osf.io/r3zm4">[Paper] </a><a target="_blank" rel="noopener" href="https://osf.io/m6pbv/?view_only=f42e460cb5d14277b70ed1ae32627af8"> [Data]</a></div><div class="post-content"><p>In developmental psychology, one of the questions that garners the attention of clinicians and experimental psychologists is caregiver bias in child’s psychological problems reports. Different models suggested by developmental psychology (e.g. The Depression-distortion, Accuracy and Combinatory model), had discussed the relation between the mother’s objective description of a child’s mental state and the degree of bias in her report. Recent evidence suggests that such bias could respond to a deficit in the caregiver’s ability to access, monitor and regulate their own...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/held-et-al-2023/">Held et al. (2023)</a></h3></div><div class="post-subtitle"><h4>Reinforcement learning of adaptive control strategies</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.31234/osf.io/d8p9e">[Paper] </a><a target="_blank" rel="noopener" href="https://osf.io/qdk5t/"> [Data]</a></div><div class="post-content"><p>Humans can up- or downregulate the degree to which they rely on task information for goal directed behaviour, a process often referred to as cognitive control. Adjustments in cognitive control are traditionally studied in response to experienced or expected task-rule conflict. However, recent theories suggest that people can also learn to adapt control settings through reinforcement. Across three preregistered task switching experiments (n&#x3D;415), we selectively rewarded correct performance on trials with either more (incongruent) or less (congruent) task-rule...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/torres-et-al-2023/">Torres et al. (2023)</a></h3></div><div class="post-subtitle"><h4>Not all objects are created equal: greater visual working memory for real-world objects is related to item memorability</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.31234/osf.io/v2ta5">[Paper] </a><a target="_blank" rel="noopener" href="https://osf.io/n65j9/"> [Data]</a></div><div class="post-content"><p>Visual working memory is thought to have a fixed capacity limit. However, recent evidence suggests that capacity is greater for real-world objects compared to simple features (i.e., colors). Here, we examined whether greater working memory for objects was due to greater memorability. In online samples of young adults, real-world objects were better remembered than colors, which was attributed to a higher proportion of high-confidence responses (Exp 1). Memory performance for objects was also improved compared to their scrambled counterparts (Exp 2), indicating that this...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/embrey-et-al-2023/">Embrey et al. (2023)</a></h3></div><div class="post-subtitle"><h4>Is All Mental Effort Equal? The Role of Cognitive Demand-Type on Effort Avoidance</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1016/j.cognition.2023.105440">[Paper] </a><a target="_blank" rel="noopener" href="https://osf.io/ydsau/?view_only=3de5b358275c420f86df48a9b96e720f"> [Data]</a></div><div class="post-content"><p>Humans are often termed “cognitive misers” for their aversion to mental effort. Both in and outside the laboratory people often show preference for low-effort tasks and are willing to forgo financial reward to avoid more demanding alternatives. Mental effort, however, does not seem to be ubiquitously avoided: people play crosswords, board games, and read novels, all as forms of leisure. While such activities undoubtedly require effort, the type of cognitive demands they impose appear markedly different from the tasks typically used in mental-effort research (e.g.,...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/working-memory/" title="working memory">working memory </a><a class="tag" href="/opendata/tags/effort/" title="effort">effort </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/bakst-mcguire-2023/">Bakst &amp; McGuire (2023)</a></h3></div><div class="post-subtitle"><h4>Experience-driven recalibration of learning from surprising events</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1016/j.cognition.2022.105343">[Paper] </a><a target="_blank" rel="noopener" href="https://osf.io/5pmhg"> [Data]</a></div><div class="post-content"><p>Different environments favor different patterns of adaptive learning. A surprising event that in one context would accelerate belief updating might, in another context, be downweighted as a meaningless outlier. Here, we investigated whether people would spontaneously regulate the influence of surprise on learning in response to event-by-event experiential feedback. Across two experiments, we examined whether participants performing a perceptual judgment task under spatial uncertainty (n &#x3D; 29, n &#x3D; 63) adapted their patterns of predictive gaze according to the...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/guida-et-al-2023/">Guida et al. (2023)</a></h3></div><div class="post-subtitle"><h4>The supplementary motor area and automatic cognitive control: Lack of evidence from two neuromodulation techniques</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1162/jocn_a_01954">[Paper] </a><a target="_blank" rel="noopener" href="https://osf.io/46pbq"> [Data]</a></div><div class="post-content"><p>The SMA is fundamental in planning voluntary movements and execution of some cognitive control operations. Specifically, the SMA has been known to play a dominant role in controlling goal-directed actions as well as those that are highly predicted (i.e., automatic). Yet, the essential contribution of SMA in goal-directed or automatic control of behavior is scarce. Our objective was to test the possible direct role of SMA in automatic and voluntary response inhibition. We separately applied two noninvasive brain stimulation (NIBS) inhibitory techniques over SMA: either...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/hirmas-engelmann-2023/">Hirmas &amp; Engelmann (2023)</a></h3></div><div class="post-subtitle"><h4>Impulsiveness moderates the effects of exogenous attention on the sensitivity to gains and losses in risky lotteries</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1016/j.joep.2023.102600">[Paper] </a><a target="_blank" rel="noopener" href="https://osf.io/5h6wp"> [Data]</a></div><div class="post-content"><p>Does attention have a causal impact on risky decisions? We address this question in a preregistered experiment in which participants accept or reject a series of mixed gambles while exogenously varying how information can be sampled. Specifically, in each trial participants observe the outcomes of a mixed-gamble with gains and losses presented sequentially. To isolate the causal role of attention on the decision process, we manipulate for how long a specific attribute is presented before showing the next one (e.g., 600 ms&#x2F;800 ms vs 400 ms). Our results partially...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/decisions-from-description/" title="decisions from description">decisions from description </a><a class="tag" href="/opendata/tags/time-pressure/" title="time pressure">time pressure </a><a class="tag" href="/opendata/tags/attention/" title="attention">attention </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/kneer-skoczen-2023/">Kneer &amp; Skoczeń (2023)</a></h3></div><div class="post-subtitle"><h4>Outcome effects, moral luck and the hindsight bias</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1016/j.cognition.2022.105258">[Paper] </a><a target="_blank" rel="noopener" href="https://osf.io/e2u8q"> [Data]</a></div><div class="post-content"><p>In a series of ten preregistered experiments (N &#x3D; 2043), we investigate the effect of outcome valence on judgments of probability, negligence, and culpability - a phenomenon sometimes labelled moral (and legal) luck. We found that harmful outcomes, when contrasted with neutral outcomes, lead to an increased perceived probability of harm ex post, and consequently, to a greater attribution of negligence and culpability. Rather than simply postulating hindsight bias (as is common), we employ a variety of empirical means to demonstrate that the outcome-driven asymmetry...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/pesowski-et-al-2023/">Pesowski et al. (2023)</a></h3></div><div class="post-subtitle"><h4>Interpersonal utility and children's social inferences from shared preferences</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1016/j.cognition.2022.105344">[Paper] </a><a target="_blank" rel="noopener" href="https://osf.io/hvx2m"> [Data]</a></div><div class="post-content"><p>Similarity of behaviors or attributes is often used to infer social affiliation and prosociality. Does this reflect reasoning using a simple expectation of homophily, or more complex reasoning about shared utility? We addressed this question by examining the inferences children make from similar choices when this similarity does or does not cause competition over a zero-sum resource. Four- to six-year-olds (N &#x3D; 204) saw two vignettes, each featuring three characters (a target plus two others) choosing between two types of resources. In all stories, each character...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/pettine-et-al-2023/">Pettine et al. (2023)</a></h3></div><div class="post-subtitle"><h4>Human generalization of internal representations through prototype learning with goal-directed attention</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1038/s41562-023-01543-7">[Paper] </a><a target="_blank" rel="noopener" href="https://zenodo.org/record/7186975"> [Data]</a></div><div class="post-content"><p>The world is overabundant with feature-rich information obscuring the latent causes of experience. How do people approximate the complexities of the external world with simplified internal representations that generalize to novel examples or situations? Theories suggest that internal representations could be determined by decision boundaries that discriminate between alternatives, or by distance measurements against prototypes and individual exemplars. Each provide advantages and drawbacks for generalization. We therefore developed theoretical models that leverage both...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/rens-et-al-2023/">Rens et al. (2023)</a></h3></div><div class="post-subtitle"><h4>Evidence for entropy maximisation in human free choice behaviour</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1016/j.cognition.2022.105328">[Paper] </a><a target="_blank" rel="noopener" href="https://osf.io/jcrsd"> [Data]</a></div><div class="post-content"><p>The freedom to choose between options is strongly linked to notions of free will. Accordingly, several studies have shown that individuals demonstrate a preference for choice, or the availability of multiple options, over and above utilitarian value. Yet we lack a decision-making framework that integrates preference for choice with traditional utility maximisation in free choice behaviour. Here we test the predictions of an inference-based model of decision-making in which an agent actively seeks states yielding entropy (availability of options) in addition to utility...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/gronau-et-al-2023/">Gronau et al. (2023)</a></h3></div><div class="post-subtitle"><h4>A unified account of simple and response-selective inhibition</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.31234/osf.io/aqk8d">[Paper] </a><a target="_blank" rel="noopener" href="https://osf.io/5z9vk/"> [Data]</a></div><div class="post-content"><p>Response inhibition is a key attribute of human executive control. Standard stop-signal tasks require countermanding a single response; the speed at which that response can be inhibited indexes the efficacy of the inhibitory control networks. However, more complex stopping tasks, where one or more components of a multi-component action are cancelled (i.e., response-selective stopping) cannot be explained by the independent-race model appropriate for the simple task (Logan and Cowan, 1984). Healthy human participants (n&#x3D;28; 10 male; 19-40 years) completed a...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/yeung-han-2023/">Yeung &amp; Han (2023)</a></h3></div><div class="post-subtitle"><h4>Changes in task performance and frontal cortex activation within and over sessions during the n-back task</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1038/s41598-023-30552-9">[Paper] </a><a target="_blank" rel="noopener" href="https://osf.io/u72g3/"> [Data]</a></div><div class="post-content"><p>The n-back task is a popular paradigm for studying neurocognitive processing at varying working memory loads. Although much is known about the effects of load on behavior and neural activation during n-back performance, the temporal dynamics of such effects remain unclear. Here, we investigated the within- and between-session stability and consistency of task performance and frontal cortical activation during the n-back task using functional near-infrared spectroscopy (fNIRS). Forty healthy young adults performed the 1-back and 3-back conditions three times per...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/carsten-et-al-2023/">Carsten et al. (2023)</a></h3></div><div class="post-subtitle"><h4>Movement characteristics impact decision-making and vice versa</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1038/s41598-023-30325-4">[Paper] </a><a target="_blank" rel="noopener" href="https://osf.io/dk7a2/"> [Data]</a></div><div class="post-content"><p>Previous studies suggest that humans are capable of coregulating the speed of decisions and movements if promoted by task incentives. It is unclear however whether such behavior is inherent to the process of translating decisional information into movements, beyond posing a valid strategy in some task contexts. Therefore, in a behavioral online study we imposed time constraints to either decision- or movement phases of a sensorimotor task, ensuring that coregulating decisions and movements was not promoted by task incentives. We found that participants indeed moved...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/le-pelley-newell-2023/">Le-Pelley &amp; Newell (2023)</a></h3></div><div class="post-subtitle"><h4>Reward-driven and memory-driven attentional biases automatically modulate rapid choice</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.31234/osf.io/cgs98">[Paper] </a><a target="_blank" rel="noopener" href="https://osf.io/gcj7e/"> [Data]</a></div><div class="post-content"><p>In two experiments we examined the influence of ‘history-driven’ attentional biases on choice behavior. In Experiment 1 we used a value-modulated attentional capture procedure to induce an automatic reward-related attentional bias, and found that this bias shaped choice in a subsequent task in which participants were required to pick the highest number from a briefly displayed choice array. In Experiment 2 we investigated the influence of a working memory manipulation, and found that choice in the number-selection task was influenced by the current (and prior) contents...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/banca-et-al-2023/">Banca et al. (2023)</a></h3></div><div class="post-subtitle"><h4>Action-sequence learning, habits and automaticity in obsessive-compulsive disorder</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1101/2023.02.23.23286338">[Paper] </a><a target="_blank" rel="noopener" href="https://osf.io/9xrdz/"> [Data]</a></div><div class="post-content"><p>Enhanced habit formation, greater automaticity and impaired goal&#x2F;habit arbitration in obsessive-compulsive disorder (OCD) are key hypotheses from the goal&#x2F;habit imbalance theory of compulsion which have not been directly investigated. This article tests these hypotheses using a combination of newly developed behavioral tasks. First, we trained patients with OCD and healthy controls, using a novel smartphone app, to perform chunked action sequences, previously shown to engage habit brain circuitry. The motor training was daily over one month period. There was...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/del-popolo-cristaldi-et-al-2023/">Del-Popolo-Cristaldi et al. (2023)</a></h3></div><div class="post-subtitle"><h4>Little fast, little slow, should I stay or should I go? Adapting cognitive control to local-global temporal prediction across typical development</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1371/journal.pone.0281417">[Paper] </a><a target="_blank" rel="noopener" href="https://osf.io/kj94s/"> [Data]</a></div><div class="post-content"><p>Adaptive cognitive control (CC), the ability to adjust goal-directed behavior according to changing environmental demand, can be instantiated bottom-up by implicit knowledge, including temporal predictability of task-relevant events. In S1-S2 tasks, either local (trial-by-trial hazard expectation) or global (block-by-block expectation) temporal information can induce prediction, allowing for proactive action control. Recent developmental evidence showed that adaptive CC based on global temporal prediction emerges earlier than when it is based on the local one only....</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/rhoads-et-al-2023/">Rhoads et al. (2023)</a></h3></div><div class="post-subtitle"><h4>Neurocomputational basis of learning when choices simultaneously affect both oneself and others</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.31234/osf.io/rf4x9">[Paper] </a><a target="_blank" rel="noopener" href="https://osf.io/2gnv4/"> [Data]</a></div><div class="post-content"><p>Most prosocial and antisocial behaviors affect ourselves and others simultaneously. To know whether to repeat choices that help or harm, we must learn from their outcomes. But the neurocomputational processes supporting such simultaneous learning remain poorly understood. In this pre-registered study, two independent samples (N&#x3D;89) learned to make choices that simultaneously affected themselves and another person. Detailed model comparison showed that people integrate self- and other-relevant information into a single cached value per choice, but update this value...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/rebholz-et-al-2023/">Rebholz et al. (2023)</a></h3></div><div class="post-subtitle"><h4>Bayesian advice taking: Adaptive strategy selection in sequential advice seeking</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.31234/osf.io/y8x92">[Paper] </a><a target="_blank" rel="noopener" href="https://osf.io/s9j8q/"> [Data]</a></div><div class="post-content"><p>In sampling approaches to advice taking, participants can sequentially sample multiple pieces of advice before making a final judgment. To contribute to the understanding of active advice seeking, we develop and compare different strategies for information integration from external sources, including Bayesian belief updating. In a reanalysis of empirical data, we find that participants most frequently compromise between their initial beliefs and the distributions of multiple pieces of advice sampled from others. Moreover, across all participants, compromising predicts...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/kwak-et-al-2023/">Kwak et al. (2023)</a></h3></div><div class="post-subtitle"><h4>Presaccadic attention sharpens visual acuity</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1038/s41598-023-29990-2">[Paper] </a><a target="_blank" rel="noopener" href="https://osf.io/m8ysa"> [Data]</a></div><div class="post-content"><p>Visual perception is limited by spatial resolution, the ability to discriminate fine details. Spatial resolution not only declines with eccentricity but also differs for polar angle locations around the visual field, also known as ‘performance fields’. To compensate for poor peripheral resolution, we make rapid eye movements-saccades-to bring peripheral objects into high-acuity foveal vision. Already before saccade onset, visual attention shifts to the saccade target location and prioritizes visual processing. This presaccadic shift of attention improves performance in...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/jackson-cavanagh-2023/">Jackson &amp; Cavanagh (2023)</a></h3></div><div class="post-subtitle"><h4>Reduced positive affect alters reward learning via reduced information encoding in the Reward Positivity</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1111/psyp.14276">[Paper] </a><a target="_blank" rel="noopener" href="https://doi.org/10.18112/openneuro.ds004315.v1.0.0"> [Data]</a></div><div class="post-content"><p>Reward Positivity (RewP) is a feedback-locked event-related potential component that is specifically elicited by rewarding feedback and scales with positive reward prediction error, a hallmark of reinforcement learning models. The RewP is also diminished in depression, suggesting that it may be a novel marker of anhedonia. Here, we examined if a sad mood induction offered an opportunity to causally induce a mood-related alteration of the RewP and reward-related learning. In Experiment 1 (N &#x3D; 50 total), participants were randomly assigned to previously established...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/donegan-et-al-2023/">Donegan et al. (2023)</a></h3></div><div class="post-subtitle"><h4>Using smartphones to optimise and scale-up the assessment of model-based planning</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.31234/osf.io/hpm4s">[Paper] </a><a target="_blank" rel="noopener" href="https://osf.io/u89ya/"> [Data]</a></div><div class="post-content"><p>Model-based planning is thought to protect against over-reliance on habits. It is reduced in individuals high in compulsivity, but effect sizes are small and may depend on subtle features of the tasks used to assess it. We developed a diamond-shooting smartphone game that measures model-based planning in an at-home setting, and varied the game’s structure within and across participants to assess how it affects measurement reliability and validity with respect to previously established correlates of model-based planning, with a focus on compulsivity. Increasing the...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/schizotypy/" title="schizotypy">schizotypy </a><a class="tag" href="/opendata/tags/anxiety/" title="anxiety">anxiety </a><a class="tag" href="/opendata/tags/depression/" title="depression">depression </a><a class="tag" href="/opendata/tags/compulsivity/" title="compulsivity">compulsivity </a><a class="tag" href="/opendata/tags/two-step/" title="two-step">two-step </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/jiang-mi-et-al-2023/">Jiang, Mi et al. (2023)</a></h3></div><div class="post-subtitle"><h4>Neurocomputational mechanism of real-time distributed learning on social networks</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1038/s41593-023-01258-y">[Paper] </a><a target="_blank" rel="noopener" href="https://osf.io/8rbs4/"> [Data]</a></div><div class="post-content"><p>Social networks shape our decisions by constraining what information we learn and from whom. Yet, the mechanisms by which network structures affect individual learning and decision-making remain unclear. Here, by combining a real-time distributed learning task with functional magnetic resonance imaging, computational modeling and social network analysis, we studied how humans learn from observing others’ decisions on seven-node networks with varying topological structures. We show that learning on social networks can be approximated by a well-established error-driven...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/spektor-et-al-2023/">Spektor et al. (2023)</a></h3></div><div class="post-subtitle"><h4>Absolute and relative stability of loss aversion across contexts</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.31234/osf.io/cwm2s">[Paper] </a><a target="_blank" rel="noopener" href="https://osf.io/28qzs/"> [Data]</a></div><div class="post-content"><p>Individuals’ decisions under risk tend to be in line with the notion that “losses loom larger than gains”. This loss aversion in decision making is commonly understood as a stable individual preference that is manifested across different contexts. The presumed stability and generality, which underlies the prominence of loss aversion in the literature at large, has been recently questioned by studies showing how loss aversion can disappear, and even reverse, as a function of the choice context. The present study investigated whether loss aversion reflects a trait-like...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/schneider-et-al-2023/">Schneider et al. (2023)</a></h3></div><div class="post-subtitle"><h4>Is the other-race effect in working memory due to attentional refreshing?</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.5334/joc.263">[Paper] </a><a target="_blank" rel="noopener" href="https://osf.io/n9zsg"> [Data]</a></div><div class="post-content"><p>The other-race effect is the observation that faces from another ethnicity induce worst recall performance than faces from one’s own ethnicity. This effect has been defined as a type of familiarity effect, with more familiar faces better recalled than less familiar faces. In this study, we tested the hypothesis that a working memory maintenance mechanism called attentional refreshing mediates the other-race effect and that faces from one’s own ethnicity are refreshed more efficiently than faces from other ethnicities. In two experiments, face ethnicity was orthogonally...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/zorowitz-niv-2023/">Zorowitz &amp; Niv (2023)</a></h3></div><div class="post-subtitle"><h4>Data from two-step task pilots</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.17605/OSF.IO/2TGJD"> [Data]</a></div><div class="post-content"><p>Data from N&#x3D;149 participants who completed a gamified version of the two-step task under one of three conditions: (1) stimuli from both first- and second-state choices were randomly assigned to right&#x2F;left positions on the screen on every trial; (2) stimuli from both first- and second-state choices were assigned fixed right&#x2F;left positions on the screen (i.e., unchanging across trials); or (3) stimuli from first-state choices were randomly assigned to right&#x2F;left positions on the screen on every trial. Second-state stimuli were assigned fixed...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/two-step/" title="two-step">two-step </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/dziego-et-al-2023/">Dziego et al. (2023)</a></h3></div><div class="post-subtitle"><h4>Neural and cognitive correlates of performance in dynamic multi-modal settings</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1016/j.neuropsychologia.2023.108483">[Paper] </a><a target="_blank" rel="noopener" href="https://osf.io/cxaz7"> [Data]</a></div><div class="post-content"><p>The endeavour to understand human cognition has largely relied upon investigation of task-related brain activity. However, resting-state brain activity can also offer insights into individual information processing and performance capabilities. Previous research has identified electroencephalographic resting-state characteristics (most prominently: the individual alpha frequency; IAF) that predict cognitive function. However, it has largely overlooked a second component of electrophysiological signals: aperiodic 1&#x2F;ƒ activity. The current study examined how both...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/gouret-pfeuffer-2023/">Gouret &amp; Pfeuffer (2023)</a></h3></div><div class="post-subtitle"><h4>Anticipatory saccades towards the future consequences of one's actions - an online eye tracking study</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.5334/joc.261">[Paper] </a><a target="_blank" rel="noopener" href="https://osf.io/avfbx"> [Data]</a></div><div class="post-content"><p>When an action contingently yields a predictable effect, we form bi-directional action-effect associations that allow us to anticipate both the location and timing of our actions’ effects. This is evident in anticipatory eye movements towards the future effect’s location which are performed earlier when the effect’s delay is short rather than long. Such anticipatory eye movements reflect a proactive process of effect monitoring which prepares a comparison of expected and actual effects. Here, in two online eye tracking experiments, we manipulated effect locations...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/fox-et-al-2023/">Fox et al. (2023)</a></h3></div><div class="post-subtitle"><h4>Metacognition in anxious-depression is state-dependent: an observational treatment study</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.31234/osf.io/uk7hr">[Paper] </a><a target="_blank" rel="noopener" href="https://accounts.osf.io/login?service=https://osf.io/89xzq/"> [Data]</a></div><div class="post-content"><p>Prior studies have found metacognitive impairments are linked to a transdiagnostic dimension of anxious-depression, manifesting as reduced confidence in performance (‘metacognitive bias’). However, previous work has been cross-sectional and so it is unclear if under-confidence is a trait-like marker of anxious-depression vulnerability, or if it resolves when anxious-depression improves. Data were collected as part of the ‘Precision in Psychiatry’ study, a large-scale transdiagnostic, four-week observational study of individuals initiating internet-based cognitive...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/metacognition/" title="metacognition">metacognition </a><a class="tag" href="/opendata/tags/confidence/" title="confidence">confidence </a><a class="tag" href="/opendata/tags/perceptual-decision-making/" title="perceptual decision making">perceptual decision making </a><a class="tag" href="/opendata/tags/depression/" title="depression">depression </a><a class="tag" href="/opendata/tags/clinical-trial/" title="clinical trial">clinical trial </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/mkrtchian-et-al-2023/">Mkrtchian et al. (2023)</a></h3></div><div class="post-subtitle"><h4>Reliability of decision-making and reinforcement learning computational parameters</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.5334/cpsy.86">[Paper] </a><a target="_blank" rel="noopener" href="https://osf.io/n7czx/"> [Data]</a></div><div class="post-content"><p>Computational models can offer mechanistic insight into cognition and therefore have the potential to transform our understanding of psychiatric disorders and their treatment. For translational efforts to be successful, it is imperative that computational measures capture individual characteristics reliably. To date, this issue has received little consideration. Here we examine the reliability of reinforcement learning and economic models derived from two commonly used tasks. Healthy individuals (N&#x3D;50) completed a restless four-armed bandit and a calibrated...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/multi-arm-bandit/" title="multi-arm bandit">multi-arm bandit </a><a class="tag" href="/opendata/tags/restless-bandit/" title="restless bandit">restless bandit </a><a class="tag" href="/opendata/tags/punishment/" title="punishment">punishment </a><a class="tag" href="/opendata/tags/risk-sensitivity/" title="risk sensitivity">risk sensitivity </a><a class="tag" href="/opendata/tags/test-retest/" title="test-retest">test-retest </a><a class="tag" href="/opendata/tags/decisions-from-description/" title="decisions from description">decisions from description </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/fleming-et-al-2023/">Fleming et al. (2023)</a></h3></div><div class="post-subtitle"><h4>Measuring cognitive effort without difficulty</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.3758/s13415-023-01065-9">[Paper] </a><a target="_blank" rel="noopener" href="https://osf.io/x34kn"> [Data]</a></div><div class="post-content"><p>An important finding in the cognitive effort literature has been that sensitivity to the costs of effort varies between individuals, suggesting that some people find effort more aversive than others. It has been suggested this may explain individual differences in other aspects of cognition; in particular that greater effort sensitivity may underlie some of the symptoms of conditions such as depression and schizophrenia. In this paper, we highlight a major problem with existing measures of cognitive effort that hampers this line of research, specifically the confounding...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/cognitive-control/" title="cognitive control">cognitive control </a><a class="tag" href="/opendata/tags/effort/" title="effort">effort </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/kristjansson-kristjansson-2023/">Kristjansson &amp; Kristjansson (2023)</a></h3></div><div class="post-subtitle"><h4>Attentional priming in Go No-Go search tasks</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.31234/osf.io/6h5pk">[Paper] </a><a target="_blank" rel="noopener" href="https://osf.io/rdnq3/"> [Data]</a></div><div class="post-content"><p>Go&#x2F;No-Go responses in visual search yield different estimates of the properties of visual search than more standard present and absent tasks. Such minor methodological tweaks have a surprisingly large effect on measures that have, for the last half-century or so, formed the backbone of prominent theories of visual attention. Secondly, priming effects in visual search have a dominating influence on visual search, accounting for effects that have been attributed to top-down guidance in standard theories. Priming effects in visual search have never been investigated...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/cognitive-control/" title="cognitive control">cognitive control </a><a class="tag" href="/opendata/tags/attention/" title="attention">attention </a><a class="tag" href="/opendata/tags/go-no-go-task/" title="go/no-go task">go/no-go task </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/makarov-et-al-2023/">Makarov et al. (2023)</a></h3></div><div class="post-subtitle"><h4>The effects of visual and auditory synchrony on human foraging</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.31234/osf.io/73rct">[Paper] </a><a target="_blank" rel="noopener" href="https://osf.io/xu5rd/"> [Data]</a></div><div class="post-content"><p>Can synchrony in stimulation guide attention and aid perceptual performance? Here, in a series of three experiments, we tested the influence of visual and auditory synchrony on attentional selection during a visual foraging task. Experiment 1 was performed online, where the task was to forage for 10 (out of 20) vertical lines among 60 randomly oriented distractor lines that changed color between yellow and blue at random intervals. The targets either changed colors in visual synchrony or not. In another condition, a non-spatial sound additionally occurred synchronously...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/visual-perception/" title="visual perception">visual perception </a><a class="tag" href="/opendata/tags/auditory-perception/" title="auditory perception">auditory perception </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/schaaf-et-al-2023/">Schaaf et al. (2023)</a></h3></div><div class="post-subtitle"><h4>Test-retest reliability of reinforcement learning parameters</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.31234/osf.io/chq5a">[Paper] </a><a target="_blank" rel="noopener" href="https://osf.io/pe23t/"> [Data]</a></div><div class="post-content"><p>Recently it has been suggested that parameters estimates of computational models can be used to understand individual differences at the process level. One area of research in which this approach, called computational phenotyping, took hold is computational psychiatry, but it is also used to understand differences in age and personality. One requirement for successful computational phenotyping is that behavior and parameters are stable over time. Surprisingly, the test-retest reliability of behavior and model parameters remains unknown for most experimental tasks and...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/2-arm-bandit/" title="2-arm bandit">2-arm bandit </a><a class="tag" href="/opendata/tags/punishment/" title="punishment">punishment </a><a class="tag" href="/opendata/tags/reversal-learning/" title="reversal learning">reversal learning </a><a class="tag" href="/opendata/tags/test-retest/" title="test-retest">test-retest </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/wimmer-et-al-2023/">Wimmer et al. (2023)</a></h3></div><div class="post-subtitle"><h4>Distinct replay signatures for prospective decision-making and memory preservation</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1073/pnas.2205211120">[Paper] </a><a target="_blank" rel="noopener" href="https://osf.io/szjxp/"> [Data]</a></div><div class="post-content"><p>Theories of neural replay propose that it supports a range of functions, most prominently planning and memory consolidation. Here, we test the hypothesis that distinct signatures of replay in the same task are related to model-based decision-making (“planning”) and memory preservation. We designed a reward learning task wherein participants utilized structure knowledge for model-based evaluation, while at the same time had to maintain knowledge of two independent and randomly alternating task environments. Using magnetoencephalography and multivariate analysis, we first...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/memory/" title="memory">memory </a><a class="tag" href="/opendata/tags/m-eeg/" title="m/eeg">m/eeg </a><a class="tag" href="/opendata/tags/sequential-decision-making/" title="sequential decision making">sequential decision making </a><a class="tag" href="/opendata/tags/two-step/" title="two-step">two-step </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/otsuka-yotsumoto-2023/">Otsuka &amp; Yotsumoto (2023)</a></h3></div><div class="post-subtitle"><h4>Near-optimal integration of the magnitude Information of time and numerosity</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1101/2023.02.01.526584">[Paper] </a><a target="_blank" rel="noopener" href="https://osf.io/bx4qt/"> [Data]</a></div><div class="post-content"><p>Magnitude information is often correlated in the external world, providing complementary information about the environment. As if to reflect this relationship, the perceptions of different magnitudes (e.g., time and numerosity) are known to influence one another. Recent studies suggest that such magnitude interaction is similar to cue integration, such as multisensory integration. Here, we tested whether human observers could integrate the magnitudes of two quantities with distinct physical units (i.e., time and numerosity) as abstract magnitude information. The...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/time-perception/" title="time perception">time perception </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/bartsch-oberauer-2023/">Bartsch &amp; Oberauer (2023)</a></h3></div><div class="post-subtitle"><h4>The contribution of episodic long-term memory to working memory for bindings</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1016/j.cognition.2022.105330">[Paper] </a><a target="_blank" rel="noopener" href="https://osf.io/ymgkq"> [Data]</a></div><div class="post-content"><p>The present experiments support two conclusions about the capacity limit of working memory (WM). First, they provide evidence for the Binding Hypothesis, WM capacity is limited by interference between bindings but not items. Second, they show that episodic LTM contributes substantially to binding memory when the capacity of WM is stretched to the limit by larger set sizes. We tested immediate memory for sets of word-picture pairs. With increasing set size, memory for bindings declined more precipitously than memory for items, as predicted from the binding hypothesis....</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/cai-pleskac-2023/">Cai &amp; Pleskac (2023)</a></h3></div><div class="post-subtitle"><h4>When alternative hypotheses shape your beliefs: Context effects in probability judgments</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1016/j.cognition.2022.105306">[Paper] </a><a target="_blank" rel="noopener" href="https://osf.io/3h7v4"> [Data]</a></div><div class="post-content"><p>When people are asked to estimate the probability of an event occurring, they sometimes make different subjective probability judgments for different descriptions of the same event. This implies the evidence or support recruited to make these judgments is based on the descriptions of the events (hypotheses) instead of the events themselves, as captured by Tversky and Koehler’s (1994) support theory. Support theory, however, assumes each hypothesis elicits a fixed level of support (support invariance). Here, across three studies, we tested this support invariance...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/horwath-et-al-2023/">Horwath et al. (2023)</a></h3></div><div class="post-subtitle"><h4>Value restructures the organization of free recall</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1016/j.cognition.2022.105315">[Paper] </a><a target="_blank" rel="noopener" href="https://osf.io/tf4rd"> [Data]</a></div><div class="post-content"><p>A large body of research illustrates the prioritization of goal-relevant information in memory; however, it is unclear how reward-related memories are organized. Using a rewarded free recall paradigm, we investigated how reward motivation structures the organization of memory around temporal and higher-order contexts. To better understand these processes, we simulated our findings using a reward-modulated variant of the Context Maintenance and Retrieval Model (CMR; Polyn et al., 2009). In the first study, we found that reward did not influence temporal clustering, but...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/memory/" title="memory">memory </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/liao-et-al-2023/">Liao et al. (2023)</a></h3></div><div class="post-subtitle"><h4>Seeing an auditory object: Pupillary light response reflects covert attention to auditory space and object</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1162/jocn_a_01935">[Paper] </a><a target="_blank" rel="noopener" href="https://github.com/hsiniliao/PLR_AuditoryObject"> [Data]</a></div><div class="post-content"><p>Attention to the relevant object and space is the brain’s strategy to effectively process the information of interest in complex environments with limited neural resources. Numerous studies have documented how attention is allocated in the visual domain, whereas the nature of attention in the auditory domain has been much less explored. Here, we show that the pupillary light response can serve as a physiological index of auditory attentional shift and can be used to probe the relationship between space-based and object-based attention as well. Experiments demonstrated...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/marchant-et-al-2023/">Marchant et al. (2023)</a></h3></div><div class="post-subtitle"><h4>Uncertainty can explain apparent mistakes in causal reasoning</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.31234/osf.io/pf9sq">[Paper] </a><a target="_blank" rel="noopener" href="https://osf.io/6xa7m/?view_only=fbe75e48fee84efb84c9167861835f02"> [Data]</a></div><div class="post-content"><p>Humans excel at causal reasoning, yet at the same time consistently fail to respect its basic axioms. They seemingly fail to recognize, for instance, that only the direct causes of an event can affect its probability (the Markov condition). How can one explain this paradox? Here we argue that standard normative analyses of causal reasoning mostly apply to the idealized case where the reasoner has perfect confidence in her knowledge of the underlying causal model. Given uncertainty about the correct representation of a causal system, it is not always rational for a...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/causal-reasoning/" title="causal reasoning">causal reasoning </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/otsuka-2023/">Otsuka (2023)</a></h3></div><div class="post-subtitle"><h4>Visual statistical learning based on time information</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1037/xge0001276">[Paper] </a><a target="_blank" rel="noopener" href="https://osf.io/cty7v/"> [Data]</a></div><div class="post-content"><p>People can extract and learn statistical regularities from various aspects of everyday life. The current study examined whether people have a mechanism to learn regularity based on time information and investigated whether sensitivity to time information is modulated by individual time management. In the familiarization phase, participants were required to observe a visual sequence of objects. Although the objects were presented in a random order, the amount of time for which the objects were presented was organized into successive triplets (e.g., 850-1,000-700 ms). In...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/quillien-2023/">Quillien (2023)</a></h3></div><div class="post-subtitle"><h4>Rational information search in welfare-tradeoff cognition</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1016/j.cognition.2022.105317">[Paper] </a><a target="_blank" rel="noopener" href="https://osf.io/jtavm"> [Data]</a></div><div class="post-content"><p>One of the most important dimensions along which we evaluate others is their propensity to value our welfare: we like people who are disposed to incur costs for our benefit and who refrain from imposing costs on us to benefit themselves. The evolutionary importance of social valuation in our species suggests that humans have cognitive mechanisms that are able to efficiently extract information about how much another person values them. Here I test the hypothesis that people are spontaneously interested in the kinds of events that have the most potential to reveal such...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/rmus-et-al-2023a/">Rmus et al. (2023a)</a></h3></div><div class="post-subtitle"><h4>Choice Type Impacts Human Reinforcement Learning</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1162/jocn_a_01947">[Paper] </a><a target="_blank" rel="noopener" href="https://osf.io/vehtk/?view_only=b05b15c7301f4214bb12080ad690935b"> [Data]</a></div><div class="post-content"><p>In reinforcement learning (RL) experiments, participants learn to make rewarding choices in response to different stimuli; RL models use outcomes to estimate stimulus–response values that change incrementally. RL models consider any response type indiscriminately, ranging from more concretely defined motor choices (pressing a key with the index finger), to more general choices that can be executed in a number of ways (selecting dinner at the restaurant). However, does the learning process vary as a function of the choice type? In Experiment 1, we show that it does:...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/multi-arm-bandit/" title="multi-arm bandit">multi-arm bandit </a><a class="tag" href="/opendata/tags/working-memory/" title="working memory">working memory </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/saint-aubin-et-al-2023/">Saint-Aubin et al. (2023)</a></h3></div><div class="post-subtitle"><h4>Modeling verbal short-term memory: A walk around the neighborhood</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1037/xlm0001226">[Paper] </a><a target="_blank" rel="noopener" href="https://osf.io/ga49s"> [Data]</a></div><div class="post-content"><p>When remembering over the short-term, long-term knowledge has a large effect on the number of correctly recalled items and little impact on memory for order. This is true, for example, when the effects of semantic category are examined. Contrary to what these findings suggest, Poirier et al. in 2015 proposed that memory for order relies on the level of activation within long-term networks. Importantly, although their view has been criticized, they showed that manipulating semantic associations led to item migrations that were atypical. In this article, we show that...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/schultz-et-al-2023/">Schultz et al. (2023)</a></h3></div><div class="post-subtitle"><h4>A reward effect on memory retention, consolidation, and generalization?</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.31234/osf.io/89s2k">[Paper] </a><a target="_blank" rel="noopener" href="https://osf.io/6vhgr/"> [Data]</a></div><div class="post-content"><p>Reward improves memory through both encoding and consolidation processes. In this pre-registered study, we tested whether reward effects on memory generalize from rewarded items to unrewarded but episodically-related items. 59 human volunteers incidentally encoded associations between unique objects and repeated scenes. Some scenes typically yielded high reward, whereas others typically yielded low reward. Memory was tested immediately after encoding (n&#x3D;29) or the next day (n&#x3D;30). Overall, reward had only a limited influence on memory. It neither enhanced...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/memory/" title="memory">memory </a></div></div></div></div><div class="pagination"><ul class="clearfix"><li class="pre pagbuttons"><a class="btn" role="navigation" href="/opendata/page/5/">Previous</a></li><li class="next pagbuttons"><a class="btn" role="navigation" href="/opendata/page/7/">Next</a></li></ul></div></div></div></div><script src="/opendata/js/jquery-migrate-1.2.1.min.js"></script><script src="/opendata/js/jquery.appear.js"></script><script src="/opendata/js/add-bookmark.js"></script><script>(function(window){var INSIGHT_CONFIG={TRANSLATION:{POSTS:"Posts",PAGES:"Pages",CATEGORIES:"Categories",TAGS:"Tags",UNTITLED:"(Untitled)",},CONTENT_URL:"/opendata/content.json",};window.INSIGHT_CONFIG=INSIGHT_CONFIG})(window);</script><script src="/opendata/js/insight.js" defer></script><div class="searchbox ins-search"><div class="searchbox-container ins-search-container"><div class="searchbox-input-wrapper"><input class="searchbox-input ins-search-input" type="text" placeholder="Search..."><span class="searchbox-close"><a class="fa fa-times-circle" onclick="closeWindow();"></a></span></div><div class="searchbox-result-wrapper ins-section-wrapper"><div class="ins-section-container"><p>Seraching...</p></div></div></div></div></body></html>