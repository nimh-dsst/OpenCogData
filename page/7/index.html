<!DOCTYPE html><html lang="zh-CN"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta name="author" content="Niv Lab"><title>OpenData</title><meta name="description" content="A collection of publicly available&lt;br&gt;behavioral datasets"><meta name="keywords"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="renderer" content="webkit"><link rel="shortcut icon" type="image/x-icon" href="/images/favicon.webp"><link rel="stylesheet" href="/opendata/css/style.css"><link rel="stylesheet" href="/opendata/css/blog_basic.css"><link rel="stylesheet" href="/opendata/css/font-awesome.min.css"><link rel="stylesheet" href="/opendata/css/insight.css"><link rel="stylesheet" href="/opendata/css/search.css"><link rel="alternate" type="application/atom+xml" title="ATOM 1.0" href="/atom.xml"><script src="/opendata/js/jquery.js"></script><!-- Global site tag (gtag.js) - Google Analytics--><script async src="https://www.googletagmanager.com/gtag/js?id=G-PTJE4Z001J"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-PTJE4Z001J');</script><meta name="generator" content="Hexo 6.3.0"></head><body><div class="page-top animated fadeInDown"><div class="nav"><li><a href="/opendata">Home</a></li><li><a href="/opendata/archives">Archives</a></li><li><a href="/opendata/tags">Tags</a></li><li><a href="/opendata/about">About</a></li><li><a href="/opendata/contribute">Contribute</a></li></div><div class="information"><div class="nav_right_btn"><li><a class="fa fa-chevron-left" onclick="window.history.go(-1)" style="display:none;"></a></li><li><a class="fa fa-search" onclick="openWindow();"></a></li></div><div class="avatar"><img src="/opendata/images/logo.webp" alt="favicon"></div></div></div><div class="sidebar animated fadeInDown"><div class="sidebar-top"><div class="logo-title"><div class="title"><img src="/opendata/images/logo.webp" style="width:175px;" alt="favicon"><h3 title=""><a href="/opendata">OpenData</a></h3><div class="description"><p>A collection of publicly available<br>behavioral datasets</p></div></div><ul class="social-links"><li><a target="_blank" rel="noopener" href="https://github.com/nivlab/opendata"><i class="fa fa-github"></i></a></li></ul></div></div><div class="footer"><div class="p"> <span> MIT License </span><i class="fa fa-star"></i><span> Niv Lab</span></div><div class="by_farbox"><span>Powered by </span><a href="https://hexo.io/zh-cn/" target="_blank">Hexo </a><span> & </span><span>Anatolo </span></div><div class="beian"></div></div></div><div class="main"><div class="autopagerize_page_element"><div class="content"><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/fung-et-al-2019/">Fung et al. (2019)</a></h3></div><div class="post-subtitle"><h4>Slow escape decisions are swayed by trait anxiety</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1038/s41562-019-0595-5">[Paper] </a><a target="_blank" rel="noopener" href="https://osf.io/c4qbr/"> [Data]</a></div><div class="post-content"><p>Theoretical models distinguish between neural responses elicited by distal threats and those evoked by more immediate threats1-3. Specifically, slower cognitive fear responses towards distal threats involve a network of brain regions including the ventral hippocampus (vHPC) and medial prefrontal cortex (mPFC), while immediate reactive fear responses rely on regions such as the periaqueductal grey4,5. However, it is unclear how anxiety and its neural substrates relate to these distinct defensive survival circuits. We tested whether individual differences in trait anxiety...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/anxiety/" title="anxiety">anxiety </a><a class="tag" href="/opendata/tags/sequential-decision-making/" title="sequential decision making">sequential decision making </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/jang-et-al-2019/">Jang et al. (2019)</a></h3></div><div class="post-subtitle"><h4>Positive reward prediction errors during decision-making strengthen memory encoding</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1038/s41562-019-0597-3">[Paper] </a><a target="_blank" rel="noopener" href="https://sites.brown.edu/mattlab/files/2019/06/jang2019_codeAndData.zip"> [Data]</a></div><div class="post-content"><p>Dopamine is thought to provide reward prediction error signals to temporal lobe memory systems, but the role of these signals in episodic memory has not been fully characterized. Here we developed an incidental memory paradigm to (i) estimate the influence of reward prediction errors on the formation of episodic memories, (ii) dissociate this influence from surprise and uncertainty, (iii) characterize the role of temporal correspondence between prediction error and memoranda presentation and (iv) determine the extent to which this influence is dependent on memory...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/memory/" title="memory">memory </a><a class="tag" href="/opendata/tags/2-arm-bandit/" title="2-arm bandit">2-arm bandit </a><a class="tag" href="/opendata/tags/counterfactual-feedback/" title="counterfactual feedback">counterfactual feedback </a><a class="tag" href="/opendata/tags/volatility/" title="volatility">volatility </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/mcdougle-et-al-2019/">McDougle et al. (2019)</a></h3></div><div class="post-subtitle"><h4>Neural Signatures of Prediction Errors in a Decision-Making Task Are Modulated by Action Execution Failures</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1016/j.cub.2019.04.011">[Paper] </a><a target="_blank" rel="noopener" href="http://osf.io/d564h"> [Data]</a></div><div class="post-content"><p>Decisions must be implemented through actions, and actions are prone to error. As such, when an expected outcome is not obtained, an individual should be sensitive to not only whether the choice itself was suboptimal but also whether the action required to indicate that choice was executed successfully. The intelligent assignment of credit to action execution versus action selection has clear ecological utility for the learner. To explore this, we used a modified version of a classic reinforcement learning task in which feedback indicated whether negative prediction...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/multi-arm-bandit/" title="multi-arm bandit">multi-arm bandit </a><a class="tag" href="/opendata/tags/agency/" title="agency">agency </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/ballard-et-al-2019b/">Ballard et al. (2019b)</a></h3></div><div class="post-subtitle"><h4>Information processing under reward versus under punishment</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1177/0956797619835462">[Paper] </a><a target="_blank" rel="noopener" href="https://osf.io/kwvu6"> [Data]</a></div><div class="post-content"><p>Much is known about the effects of reward and punishment on behavior, yet little research has considered how these incentives influence the information-processing dynamics that underlie decision making. We fitted the linear ballistic accumulator to data from a perceptual-judgment task to examine the impacts of reward- and punishment-based incentives on three distinct components of information processing: the quality of the information processed, the quantity of that information, and the decision threshold. The threat of punishment lowered the average quality and...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/perceptual-decision-making/" title="perceptual decision making">perceptual decision making </a><a class="tag" href="/opendata/tags/punishment/" title="punishment">punishment </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/widge-et-al-2019/">Widge et al. (2019)</a></h3></div><div class="post-subtitle"><h4>Effects of ON/OFF deep brain stimulation on cognitive control in treatment-resistant depression</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1038/s41467-019-09557-4">[Paper] </a><a target="_blank" rel="noopener" href="https://openneuro.org/datasets/ds001784"> [Data]</a></div><div class="post-content"><p>Deep brain stimulation (DBS) is a circuit-oriented treatment for mental disorders. Unfortunately, even well-conducted psychiatric DBS clinical trials have yielded inconsistent symptom relief, in part because DBS mechanism(s) of action are unclear. One clue to those mechanisms may lie in the efficacy of ventral internal capsule&#x2F;ventral striatum (VCVS) DBS in both major depression (MDD) and obsessive-compulsive disorder (OCD). MDD and OCD both involve deficits in cognitive control. Cognitive control depends on prefrontal cortex (PFC) regions that project into the...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/m-eeg/" title="m/eeg">m/eeg </a><a class="tag" href="/opendata/tags/cognitive-control/" title="cognitive control">cognitive control </a><a class="tag" href="/opendata/tags/depression/" title="depression">depression </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/mcdonald-et-al-2019/">McDonald et al. (2019)</a></h3></div><div class="post-subtitle"><h4>Bayesian nonparametric models characterize instantaneous strategies in a competitive dynamic game</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1038/s41467-019-09789-4">[Paper] </a><a target="_blank" rel="noopener" href="https://osf.io/evfg5/"> [Data]</a></div><div class="post-content"><p>Previous studies of strategic social interaction in game theory have predominantly used games with clearly-defined turns and limited choices. Yet, most real-world social behaviors involve dynamic, coevolving decisions by interacting agents, which poses challenges for creating tractable models of behavior. Here, using a game in which humans competed against both real and artificial opponents, we show that it is possible to quantify the instantaneous dynamic coupling between agents. Adopting a reinforcement learning approach, we use Gaussian Processes to model the policy...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/social-decision-making/" title="social decision making">social decision making </a><a class="tag" href="/opendata/tags/sequential-decision-making/" title="sequential decision making">sequential decision making </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/thomas-et-al-2019/">Thomas et al. (2019)</a></h3></div><div class="post-subtitle"><h4>Gaze bias differences capture individual choice behaviour</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1038/s41562-019-0584-8">[Paper] </a><a target="_blank" rel="noopener" href="http://www.github.com/glamlab/gaze-bias-differences"> [Data]</a></div><div class="post-content"><p>How do we make simple choices such as deciding between an apple and an orange? Recent empirical evidence suggests that choice behaviour and gaze allocation are closely linked at the group level, whereby items looked at longer during the decision-making process are more likely to be chosen. However, it is unclear how variable this gaze bias effect is between individuals. Here we investigate this question across four different simple choice experiments and using a computational model that can be easily applied to individuals. We show that an association between gaze and...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/2-arm-bandit/" title="2-arm bandit">2-arm bandit </a><a class="tag" href="/opendata/tags/perceptual-decision-making/" title="perceptual decision making">perceptual decision making </a><a class="tag" href="/opendata/tags/eye-tracking/" title="eye-tracking">eye-tracking </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/bae-luck-2019/">Bae &amp; Luck (2019)</a></h3></div><div class="post-subtitle"><h4>Reactivation of previous experiences in a working memory task</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1177/0956797619830398">[Paper] </a><a target="_blank" rel="noopener" href="https://osf.io/dbgh6"> [Data]</a></div><div class="post-content"><p>Recent experiences influence the processing of new information even when those experiences are irrelevant to the current task. Does this reflect the indirect effects of a passively maintained representation of the previous experience, or is this representation reactivated when a new event occurs? To answer this question, we attempted to decode the orientation of the stimulus on the previous trial from the electroencephalogram on the current trial in a working memory task. Behavioral data confirmed that the previous-trial stimulus orientation influenced the reported...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/m-eeg/" title="m/eeg">m/eeg </a><a class="tag" href="/opendata/tags/working-memory/" title="working memory">working memory </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/hakim-et-al-2019/">Hakim et al. (2019)</a></h3></div><div class="post-subtitle"><h4>Dissecting the neural focus of attention reveals distinct processes for spatial attention and object-based storage in visual working memory</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1177/0956797619830384">[Paper] </a><a target="_blank" rel="noopener" href="https://osf.io/ws3j9/"> [Data]</a></div><div class="post-content"><p>Complex cognition relies on both on-line representations in working memory (WM), said to reside in the focus of attention, and passive off-line representations of related information. Here, we dissected the focus of attention by showing that distinct neural signals index the on-line storage of objects and sustained spatial attention. We recorded electroencephalogram (EEG) activity during two tasks that employed identical stimulus displays but varied the relative demands for object storage and spatial attention. We found distinct delay-period signatures for an attention...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/m-eeg/" title="m/eeg">m/eeg </a><a class="tag" href="/opendata/tags/working-memory/" title="working memory">working memory </a><a class="tag" href="/opendata/tags/attention/" title="attention">attention </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/piray-et-al-2019/">Piray et al. (2019)</a></h3></div><div class="post-subtitle"><h4>Emotionally Aversive Cues Suppress Neural Systems Underlying Optimal Learning in Socially Anxious Individuals</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1523/JNEUROSCI.1394-18.2018">[Paper] </a><a target="_blank" rel="noopener" href="https://github.com/payampiray/piray_etal_2019_JNeurosci"> [Data]</a></div><div class="post-content"><p>Learning and decision-making are modulated by socio-emotional processing and such modulation is implicated in clinically relevant personality traits of social anxiety. The present study elucidates the computational and neural mechanisms by which emotionally aversive cues disrupt learning in socially anxious human individuals. Healthy volunteers with low or high trait social anxiety performed a reversal learning task requiring learning actions in response to angry or happy face cues. Choice data were best captured by a computational model in which learning rate was...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/2-arm-bandit/" title="2-arm bandit">2-arm bandit </a><a class="tag" href="/opendata/tags/anxiety/" title="anxiety">anxiety </a><a class="tag" href="/opendata/tags/reversal-learning/" title="reversal learning">reversal learning </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/olschewski-et-al-2019/">Olschewski et al. (2019)</a></h3></div><div class="post-subtitle"><h4>How Basic Cognition Influences Experience-Based Economic Valuation</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.31219/osf.io/4st52">[Paper] </a><a target="_blank" rel="noopener" href="https://osf.io/ehkuz/"> [Data]</a></div><div class="post-content"><p>The perception and integration of sequential numerical information is a common cognitive task. It is a prerequisite for experience-based economic choices, but it is usually not part of economic decision theory. To better understand the process of symbolic number integration and its influence on economic behavior, we performed three experimental studies that examined mean estimates and economic valuations of continuous number distributions. The results indicate that participants valued random number distributions below their respective arithmetic means and valued...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/risk-sensitivity/" title="risk sensitivity">risk sensitivity </a><a class="tag" href="/opendata/tags/sequential-sampling/" title="sequential sampling">sequential sampling </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/zhu-et-al-2019/">Zhu et al. (2019)</a></h3></div><div class="post-subtitle"><h4>Patients with basal ganglia damage show preserved learning in an economic game</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1038/s41467-019-08766-1">[Paper] </a><a target="_blank" rel="noopener" href="https://osf.io/4x3nf/"> [Data]</a></div><div class="post-content"><p>Both basal ganglia (BG) and orbitofrontal cortex (OFC) have been widely implicated in social and non-social decision-making. However, unlike OFC damage, BG pathology is not typically associated with disturbances in social functioning. Here we studied the behavior of patients with focal lesions to either BG or OFC in a multi-strategy competitive game known to engage these regions. We find that whereas OFC patients are significantly impaired, BG patients show intact learning in the economic game. By contrast, when information about the strategic context is absent, both...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/social-decision-making/" title="social decision making">social decision making </a><a class="tag" href="/opendata/tags/economic-game/" title="economic game">economic game </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/dombrovski-et-al-2019/">Dombrovski et al. (2019)</a></h3></div><div class="post-subtitle"><h4>Value-Based Choice, Contingency Learning, and Suicidal Behavior in Mid- and Late-Life Depression</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1016/j.biopsych.2018.10.006">[Paper] </a><a target="_blank" rel="noopener" href="https://github.com/DecisionNeurosciencePsychopathology/bandit_pub"> [Data]</a></div><div class="post-content"><p>Suicidal behavior is associated with impaired decision making in contexts of uncertainty. Existing studies, however, do not definitively address whether suicide attempers have 1) impairment in learning from experience or 2) impairment in choice based on comparison of estimated option values. Our reinforcement learning model-based behavioral study tested these hypotheses directly in middle-aged and older suicide attempters representative of those who die by suicide. Two samples (sample 1, n &#x3D; 135; sample 2, n &#x3D; 125) of suicide attempters with depression...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/multi-arm-bandit/" title="multi-arm bandit">multi-arm bandit </a><a class="tag" href="/opendata/tags/depression/" title="depression">depression </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/moran-et-al-2019/">Moran et al. (2019)</a></h3></div><div class="post-subtitle"><h4>Retrospective Model-Based inference Guides Model-Free Credit Assignment</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1038/s41467-019-08662-8">[Paper] </a><a target="_blank" rel="noopener" href="https://osf.io/8j7yf/"> [Data]</a></div><div class="post-content"><p>An extensive reinforcement learning literature shows that organisms assign credit efficiently, even under conditions of state uncertainty. However, little is known about credit-assignment when state uncertainty is subsequently resolved. Here, we address this problem within the framework of an interaction between model-free (MF) and model-based (MB) control systems. We present and support experimentally a theory of MB retrospective-inference. Within this framework, a MB system resolves uncertainty that prevailed when actions were taken thus guiding an MF...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/restless-bandit/" title="restless bandit">restless bandit </a><a class="tag" href="/opendata/tags/sequential-decision-making/" title="sequential decision making">sequential decision making </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/ballard-et-al-2019a/">Ballard et al. (2019a)</a></h3></div><div class="post-subtitle"><h4>Hippocampal pattern separation supports reinforcement learning</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1038/s41467-019-08998-1">[Paper] </a><a target="_blank" rel="noopener" href="https://openneuro.org/datasets/ds001590"> [Data]</a></div><div class="post-content"><p>Animals rely on learned associations to make decisions. Associations can be based on relationships between object features (e.g., the three leaflets of poison ivy leaves) and outcomes (e.g., rash). More often, outcomes are linked to multidimensional states (e.g., poison ivy is green in summer but red in spring). Feature-based reinforcement learning fails when the values of individual features depend on the other features present. One solution is to assign value to multi-featural conjunctive representations. Here, we test if the hippocampus forms separable conjunctive...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/configural-learning/" title="configural learning">configural learning </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/dorfman-et-al-2019/">Dorfman et al. (2019)</a></h3></div><div class="post-subtitle"><h4>Causal Inference About Good and Bad Outcomes</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1177/0956797619828724">[Paper] </a><a target="_blank" rel="noopener" href="https://osf.io/3htpj/"> [Data]</a></div><div class="post-content"><p>People learn differently from good and bad outcomes. We argue that valence-dependent learning asymmetries are partly driven by beliefs about the causal structure of the environment. If hidden causes can intervene to generate bad (or good) outcomes, then a rational observer will assign blame (or credit) to these hidden causes, rather than to the stable outcome distribution. Thus, a rational observer should learn less from bad outcomes when they are likely to have been generated by a hidden cause, and this pattern should reverse when hidden causes are likely to generate...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/social-decision-making/" title="social decision making">social decision making </a><a class="tag" href="/opendata/tags/latent-cause-inference/" title="latent cause inference">latent cause inference </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/shahar-et-al-2019/">Shahar et al. (2019)</a></h3></div><div class="post-subtitle"><h4>Improving the reliability of model-based decision-making estimates in the two-stage decision task with reaction-times and drift-diffusion modeling</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1371/journal.pcbi.1006803">[Paper] </a><a target="_blank" rel="noopener" href="https://osf.io/zc24g/?view_only=d7f00134186c411986cc4de46b38edc5"> [Data]</a></div><div class="post-content"><p>A well-established notion in cognitive neuroscience proposes that multiple brain systems contribute to choice behaviour. These include: (1) a model-free system that uses values cached from the outcome history of alternative actions, and (2) a model-based system that considers action outcomes and the transition structure of the environment. The widespread use of this distinction, across a range of applications, renders it important to index their distinct influences with high reliability. Here we consider the two-stage task, widely considered as a gold standard measure...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/development/" title="development">development </a><a class="tag" href="/opendata/tags/adolescence/" title="adolescence">adolescence </a><a class="tag" href="/opendata/tags/test-retest/" title="test-retest">test-retest </a><a class="tag" href="/opendata/tags/two-step/" title="two-step">two-step </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/homan-et-al-2019/">Homan et al. (2019)</a></h3></div><div class="post-subtitle"><h4>Neural computations of threat in the aftermath of combat trauma</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1038/s41593-018-0315-x">[Paper] </a><a target="_blank" rel="noopener" href="https://osf.io/rxsw2/"> [Data]</a></div><div class="post-content"><p>By combining computational, morphological, and functional analyses, this study relates latent markers of associative threat learning to overt post-traumatic stress disorder (PTSD) symptoms in combat veterans. Using reversal learning, we found that symptomatic veterans showed greater physiological adjustment to cues that did not predict what they had expected, indicating greater sensitivity to prediction errors for negative outcomes. This exaggerated weighting of prediction errors shapes the dynamic learning rate (associability) and value of threat predictive cues. The...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/punishment/" title="punishment">punishment </a><a class="tag" href="/opendata/tags/reversal-learning/" title="reversal learning">reversal learning </a><a class="tag" href="/opendata/tags/ptsd/" title="ptsd">ptsd </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/cavanagh-et-al-2019/">Cavanagh et al. (2019)</a></h3></div><div class="post-subtitle"><h4>Multiple Dissociations Between Comorbid Depression and Anxiety on Reward and Punishment Processing: Evidence From Computationally Informed m/eeg</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1162/cpsy_a_00024">[Paper] </a><a target="_blank" rel="noopener" href="https://bit.ly/2F11Zwv"> [Data]</a></div><div class="post-content"><p>In this report, we provide the first evidence that mood and anxiety dimensions are associated with unique aspects of EEG responses to reward and punishment, respectively. We reanalyzed data from our prior publication of a categorical depiction of depression to address more sophisticated dimensional hypotheses. Highly symptomatic depressed individuals (N &#x3D; 46) completed a probabilistic learning task with concurrent EEG. Measures of anxiety and depression symptomatology were significantly correlated with each other; however, only anxiety predicted better avoidance...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/m-eeg/" title="m/eeg">m/eeg </a><a class="tag" href="/opendata/tags/anxiety/" title="anxiety">anxiety </a><a class="tag" href="/opendata/tags/depression/" title="depression">depression </a><a class="tag" href="/opendata/tags/probabilistic-selection-task/" title="probabilistic selection task">probabilistic selection task </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/pleskac-et-al-2019/">Pleskac et al. (2019)</a></h3></div><div class="post-subtitle"><h4>Mechanisms of deliberation during preferential choice: Perspectives from computational modeling and individual differences</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1037/dec0000092">[Paper] </a><a target="_blank" rel="noopener" href="https://osf.io/g7a49/"> [Data]</a></div><div class="post-content"><p>Computational models of decision making typically assume as people deliberate between options they mentally simulate outcomes from each one and integrate valuations of these outcomes to form a preference. In two studies, we investigated this deliberation process using a task where participants make a series of decisions between a certain and an uncertain option, which were shown as dynamic visual samples that represented possible payoffs. We developed and validated a method of reverse correlational analysis for the task that measures how this time-varying signal was...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/perceptual-decision-making/" title="perceptual decision making">perceptual decision making </a><a class="tag" href="/opendata/tags/balloon-analog-risk-task/" title="balloon analog risk task">balloon analog risk task </a><a class="tag" href="/opendata/tags/sequential-sampling/" title="sequential sampling">sequential sampling </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/moutoussis-et-al-2018/">Moutoussis et al. (2018)</a></h3></div><div class="post-subtitle"><h4>Change, stability, and instability in the Pavlovian guidance of behaviour from adolescence to young adulthood</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1371/journal.pcbi.1006679">[Paper] </a><a target="_blank" rel="noopener" href="https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1006679#sec016"> [Data]</a></div><div class="post-content"><p>Pavlovian influences are important in guiding decision-making across health and psychopathology. There is an increasing interest in using concise computational tasks to parametrise such influences in large populations, and especially to track their evolution during development and changes in mental health. However, the developmental course of Pavlovian influences is uncertain, a problem compounded by the unclear psychometric properties of the relevant measurements. We assessed Pavlovian influences in a longitudinal sample using a well characterised and widely used...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/pavlovian-go-no-go-task/" title="pavlovian go/no-go task">pavlovian go/no-go task </a><a class="tag" href="/opendata/tags/development/" title="development">development </a><a class="tag" href="/opendata/tags/adolescence/" title="adolescence">adolescence </a><a class="tag" href="/opendata/tags/test-retest/" title="test-retest">test-retest </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/wulff-et-al-2018/">Wulff et al. (2018)</a></h3></div><div class="post-subtitle"><h4>A meta-analytic review of two modes of learning and the description-experience gap.</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1037/bul0000115">[Paper] </a><a target="_blank" rel="noopener" href="https://zenodo.org/record/1491449"> [Data]</a></div><div class="post-content"><p>People can learn about the probabilistic consequences of their actions in two ways: One is by consulting descriptions of an action’s consequences and probabilities (e.g., reading up on a medication’s side effects). The other is by personally experiencing the probabilistic consequences of an action (e.g., beta testing software). In principle, people taking each route can reach analogous states of knowledge and consequently make analogous decisions. In the last dozen years, however, research has demonstrated systematic discrepancies between description- and...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/decisions-from-description/" title="decisions from description">decisions from description </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/correa-et-al-2018/">Correa et al. (2018)</a></h3></div><div class="post-subtitle"><h4>How the Level of Reward Awareness Changes the Computational and Electrophysiological Signatures of Reinforcement Learning</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1523/JNEUROSCI.0457-18.2018">[Paper] </a><a target="_blank" rel="noopener" href="https://figshare.com/articles/Codes_and_Data_-_Correa_et_al_JNeuro_2018/7987100"> [Data]</a></div><div class="post-content"><p>The extent to which subjective awareness influences reward processing, and thereby affects future decisions, is currently largely unknown. In the present report, we investigated this question in a reinforcement learning framework, combining perceptual masking, computational modeling, and electroencephalographic recordings (human male and female participants). Our results indicate that degrading the visibility of the reward decreased, without completely obliterating, the ability of participants to learn from outcomes, but concurrently increased their tendency to repeat...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/2-arm-bandit/" title="2-arm bandit">2-arm bandit </a><a class="tag" href="/opendata/tags/reversal-learning/" title="reversal learning">reversal learning </a><a class="tag" href="/opendata/tags/reward-visibility/" title="reward visibility">reward visibility </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/braun-et-al-2018/">Braun et al. (2018)</a></h3></div><div class="post-subtitle"><h4>Retroactive and graded prioritization of memory by reward</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1038/s41467-018-07280-0">[Paper] </a><a target="_blank" rel="noopener" href="https://osf.io/gz9xe/"> [Data]</a></div><div class="post-content"><p>Many decisions are based on an internal model of the world. Yet, how such a model is constructed from experience and represented in memory remains unknown. We test the hypothesis that reward shapes memory for sequences of events by retroactively prioritizing memory for objects as a function of their distance from reward. Human participants encountered neutral objects while exploring a series of mazes for reward. Across six data sets, we find that reward systematically modulates memory for neutral objects, retroactively prioritizing memory for objects closest to the...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/memory/" title="memory">memory </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/wu-et-al-2018/">Wu et al. (2018)</a></h3></div><div class="post-subtitle"><h4>Generalization guides human exploration in vast decision spaces</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1038/s41562-018-0467-4">[Paper] </a><a target="_blank" rel="noopener" href="https://github.com/charleywu/gridsearch"> [Data]</a></div><div class="post-content"><p>From foraging for food to learning complex games, many aspects of human behaviour can be framed as a search problem with a vast space of possible actions. Under finite search horizons, optimal solutions are generally unobtainable. Yet, how do humans navigate vast problem spaces, which require intelligent exploration of unobserved actions? Using various bandit tasks with up to 121 arms, we study how humans search for rewards under limited search horizons, in which the spatial correlation of rewards (in both generated and natural environments) provides traction for...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/sequential-decision-making/" title="sequential decision making">sequential decision making </a><a class="tag" href="/opendata/tags/continuous-outcomes/" title="continuous outcomes">continuous outcomes </a><a class="tag" href="/opendata/tags/generalization/" title="generalization">generalization </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/konstantinidis-et-al-2018/">Konstantinidis et al. (2018)</a></h3></div><div class="post-subtitle"><h4>Magnitude and incentives: revisiting the overweighting of extreme events in risky decisions from experience</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.3758/s13423-017-1383-8">[Paper] </a><a target="_blank" rel="noopener" href="https://osf.io/z57tn/"> [Data]</a></div><div class="post-content"><p>Recent experimental evidence in experience-based decision-making suggests that people are more risk seeking in the gains domain relative to the losses domain. This critical result is at odds with the standard reflection effect observed in description-based choice and explained by Prospect Theory. The so-called reversed-reflection effect has been predicated on the extreme-outcome rule, which suggests that memory biases affect risky choice from experience. To test the general plausibility of the rule, we conducted two experiments examining how the magnitude of prospective...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/2-arm-bandit/" title="2-arm bandit">2-arm bandit </a><a class="tag" href="/opendata/tags/risk-sensitivity/" title="risk sensitivity">risk sensitivity </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/bavard-et-al-2018/">Bavard et al. (2018)</a></h3></div><div class="post-subtitle"><h4>Reference-point centering and range-adaptation enhance human reinforcement learning at the cost of irrational preferences</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1038/s41467-018-06781-2">[Paper] </a><a target="_blank" rel="noopener" href="https://github.com/sophiebavard/Magnitude"> [Data]</a></div><div class="post-content"><p>In economics and perceptual decision-making contextual effects are well documented, where decision weights are adjusted as a function of the distribution of stimuli. Yet, in reinforcement learning literature whether and how contextual information pertaining to decision states is integrated in learning algorithms has received comparably little attention. Here, we investigate reinforcement learning behavior and its computational substrates in a task where we orthogonally manipulate outcome valence and magnitude, resulting in systematic variations in state-values. Model...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/2-arm-bandit/" title="2-arm bandit">2-arm bandit </a><a class="tag" href="/opendata/tags/range-adaptation/" title="range adaptation">range adaptation </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/swart-et-al-2018/">Swart et al. (2018)</a></h3></div><div class="post-subtitle"><h4>Frontal network dynamics reflect neurocomputational mechanisms for reducing maladaptive biases in motivated action</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1371/journal.pbio.2005979">[Paper] </a><a target="_blank" rel="noopener" href="https://data.donders.ru.nl/collections/di/dccn/DSC_3017033.03_624?0"> [Data]</a></div><div class="post-content"><p>Motivation exerts control over behavior by eliciting Pavlovian responses, which can either match or conflict with instrumental action. We can overcome maladaptive motivational influences putatively through frontal cognitive control. However, the neurocomputational mechanisms subserving this control are unclear; does control entail up-regulating instrumental systems, down-regulating Pavlovian systems, or both? We combined electroencephalography (EEG) recordings with a motivational Go&#x2F;NoGo learning task (N &#x3D; 34), in which multiple Go options enabled us to...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/pavlovian-go-no-go-task/" title="pavlovian go/no-go task">pavlovian go/no-go task </a><a class="tag" href="/opendata/tags/m-eeg/" title="m/eeg">m/eeg </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/collins-2018/">Collins (2018)</a></h3></div><div class="post-subtitle"><h4>The Tortoise and the Hare: Interactions between Reinforcement Learning and Working Memory</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1162/jocn_a_01238">[Paper] </a><a target="_blank" rel="noopener" href="https://osf.io/5gbr3/"> [Data]</a></div><div class="post-content"><p>Learning to make rewarding choices in response to stimuli depends on a slow but steady process, reinforcement learning, and a fast and flexible, but capacity-limited process, working memory. Using both systems in parallel, with their contributions weighted based on performance, should allow us to leverage the best of each system: rapid early learning, supplemented by long-term robust acquisition. However, this assumes that using one process does not interfere with the other. We use computational modeling to investigate the interactions between the two processes in a...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/working-memory/" title="working memory">working memory </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/kool-et-al-2018/">Kool et al. (2018)</a></h3></div><div class="post-subtitle"><h4>Planning complexity registers as a cost in metacontrol</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1162/jocn_a_01263">[Paper] </a><a target="_blank" rel="noopener" href="https://osf.io/793yw/"> [Data]</a></div><div class="post-content"><p>Decision-making algorithms face a basic tradeoff between accuracy and effort (i.e., computational demands). It is widely agreed that humans can choose between multiple decision-making processes that embody different solutions to this tradeoff: Some are computationally cheap but inaccurate, whereas others are computationally expensive but accurate. Recent progress in understanding this tradeoff has been catalyzed by formalizing it in terms of model-free (i.e., habitual) versus model-based (i.e., planning) approaches to reinforcement learning. Intuitively, if two tasks...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/sequential-decision-making/" title="sequential decision making">sequential decision making </a><a class="tag" href="/opendata/tags/two-step/" title="two-step">two-step </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/millner-et-al-2018/">Millner et al. (2018)</a></h3></div><div class="post-subtitle"><h4>Pavlovian Control of Escape and Avoidance</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1162/jocn_a_01224">[Paper] </a><a target="_blank" rel="noopener" href="https://osf.io/p36u5/"> [Data]</a></div><div class="post-content"><p>To survive in complex environments, animals need to have mechanisms to select effective actions quickly, with minimal computational costs. As perhaps the computationally most parsimonious of these systems, Pavlovian control accomplishes this by hardwiring specific stereotyped responses to certain classes of stimuli. It is well documented that appetitive cues initiate a Pavlovian bias toward vigorous approach; however, Pavlovian responses to aversive stimuli are less well understood. Gaining a deeper understanding of aversive Pavlovian responses, such as active...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/pavlovian-go-no-go-task/" title="pavlovian go/no-go task">pavlovian go/no-go task </a><a class="tag" href="/opendata/tags/avoidance/" title="avoidance">avoidance </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/wimmer-et-al-2018/">Wimmer et al. (2018)</a></h3></div><div class="post-subtitle"><h4>Reward learning over weeks versus minutes increases the neural representation of value in the human brain</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1523/JNEUROSCI.0075-18.2018">[Paper] </a><a target="_blank" rel="noopener" href="https://osf.io/z2gwf/"> [Data]</a></div><div class="post-content"><p>Over the past few decades, neuroscience research has illuminated the neural mechanisms supporting learning from reward feedback. Learning paradigms are increasingly being extended to study mood and psychiatric disorders as well as addiction. However, one potentially critical characteristic that this research ignores is the effect of time on learning: human feedback learning paradigms are usually conducted in a single rapidly paced session, whereas learning experiences in ecologically relevant circumstances and in animal research are almost always separated by longer...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/memory/" title="memory">memory </a><a class="tag" href="/opendata/tags/2-arm-bandit/" title="2-arm bandit">2-arm bandit </a><a class="tag" href="/opendata/tags/working-memory/" title="working memory">working memory </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/navarro-et-al-2018/">Navarro et al. (2018)</a></h3></div><div class="post-subtitle"><h4>Aversion to option loss in a restless bandit task</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1007/s42113-018-0010-8">[Paper] </a><a target="_blank" rel="noopener" href="https://osf.io/nzvqp/"> [Data]</a></div><div class="post-content"><p>In everyday life, people need to make choices without full information about the environment, which poses an explore-exploit dilemma in which one must balance the need to learn about the world and the need to obtain rewards from it. The explore-exploit dilemma is often studied using the multi-armed restless bandit task, in which people repeatedly select from multiple options, and human behaviour is modelled as a form of reinforcement learning via Kalman filters. Inspired by work in the judgment and decision-making literature, we present two experiments using multi-armed...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/explore-exploit/" title="explore/exploit">explore/exploit </a><a class="tag" href="/opendata/tags/multi-arm-bandit/" title="multi-arm bandit">multi-arm bandit </a><a class="tag" href="/opendata/tags/restless-bandit/" title="restless bandit">restless bandit </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/rouhani-et-al-2018/">Rouhani et al. (2018)</a></h3></div><div class="post-subtitle"><h4>Dissociable effects of surprising rewards on learning and memory</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1037/xlm0000518">[Paper] </a><a target="_blank" rel="noopener" href="https://nivlab.princeton.edu/sites/default/files/nivlab/files/rouhani2018_inddiff_allexps.csv"> [Data]</a></div><div class="post-content"><p>Reward-prediction errors track the extent to which rewards deviate from expectations, and aid in learning. How do such errors in prediction interact with memory for the rewarding episode? Existing findings point to both cooperative and competitive interactions between learning and memory mechanisms. Here, we investigated whether learning about rewards in a high-risk context, with frequent, large prediction errors, would give rise to higher fidelity memory traces for rewarding events than learning in a low-risk context. Experiment 1 showed that recognition was better for...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/memory/" title="memory">memory </a><a class="tag" href="/opendata/tags/continuous-outcomes/" title="continuous outcomes">continuous outcomes </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/pachur-et-al-2018/">Pachur et al. (2018)</a></h3></div><div class="post-subtitle"><h4>Prospect theory reflects selective allocation of attention.</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1037/xge0000406">[Paper] </a><a target="_blank" rel="noopener" href="https://osf.io/5semf/"> [Data]</a></div><div class="post-content"><p>There is a disconnect in the literature between analyses of risky choice based on cumulative prospect theory (CPT) and work on predecisional information processing. One likely reason is that for expectation models (e.g., CPT), it is often assumed that people behaved only as if they conducted the computations leading to the predicted choice and that the models are thus mute regarding information processing. We suggest that key psychological constructs in CPT, such as loss aversion and outcome and probability sensitivity, can be interpreted in terms of attention...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/risk-sensitivity/" title="risk sensitivity">risk sensitivity </a><a class="tag" href="/opendata/tags/decisions-from-description/" title="decisions from description">decisions from description </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/tarantola-et-al-2017/">Tarantola et al. (2017)</a></h3></div><div class="post-subtitle"><h4>Prior preferences beneficially influence social and non-social learning</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1038/s41467-017-00826-8">[Paper] </a><a target="_blank" rel="noopener" href="https://figshare.com/articles/dataset/Prior_preferences_beneficially_influence_social_and_non-social_learning/5198572"> [Data]</a></div><div class="post-content"><p>Our personal preferences affect a broad array of social behaviors. This includes the way we learn the preferences of others, an ability that often relies on limited or ambiguous information. Here we report an egocentric influence on this type of social learning that is reflected in both performance and response times. Using computational models that combine inter-trial learning and intra-trial choice, we find transient effects of participants preferences on the learning process, through the influence of priors, and persistent effects on the choice process. A second...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/2-arm-bandit/" title="2-arm bandit">2-arm bandit </a><a class="tag" href="/opendata/tags/social-decision-making/" title="social decision making">social decision making </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/frey-et-al-2017/">Frey et al. (2017)</a></h3></div><div class="post-subtitle"><h4>Risk preference shares the psychometric structure of major psychological traits</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1126/sciadv.1701381">[Paper] </a><a target="_blank" rel="noopener" href="https://osf.io/rce7g/"> [Data]</a></div><div class="post-content"><p>To what extent is there a general factor of risk preference, R, akin to g, the general factor of intelligence? Can risk preference be regarded as a stable psychological trait? These conceptual issues persist because few attempts have been made to integrate multiple risk-taking measures, particularly measures from different and largely unrelated measurement traditions (self-reported propensity measures assessing stated preferences, incentivized behavioral measures eliciting revealed preferences, and frequency measures assessing actual risky activities). Adopting a...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/sequential-decision-making/" title="sequential decision making">sequential decision making </a><a class="tag" href="/opendata/tags/risk-sensitivity/" title="risk sensitivity">risk sensitivity </a><a class="tag" href="/opendata/tags/test-retest/" title="test-retest">test-retest </a><a class="tag" href="/opendata/tags/decisions-from-description/" title="decisions from description">decisions from description </a><a class="tag" href="/opendata/tags/balloon-analog-risk-task/" title="balloon analog risk task">balloon analog risk task </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/zajkowski-et-al-2017/">Zajkowski et al. (2017)</a></h3></div><div class="post-subtitle"><h4>A causal role for right frontopolar cortex in directed, but not random, exploration</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.7554/eLife.27430">[Paper] </a><a target="_blank" rel="noopener" href="https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/CZT6EE"> [Data]</a></div><div class="post-content"><p>The explore-exploit dilemma occurs anytime we must choose between exploring unknown options for information and exploiting known resources for reward. Previous work suggests that people use two different strategies to solve the explore-exploit dilemma: directed exploration, driven by information seeking, and random exploration, driven by decision noise. Here, we show that these two strategies rely on different neural systems. Using transcranial magnetic stimulation to inhibit the right frontopolar cortex, we were able to selectively inhibit directed exploration while...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/explore-exploit/" title="explore/exploit">explore/exploit </a><a class="tag" href="/opendata/tags/horizons-task/" title="horizons task">horizons task </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/palminteri-et-al-2017/">Palminteri et al. (2017)</a></h3></div><div class="post-subtitle"><h4>Confirmation bias in human reinforcement learning: Evidence from counterfactual feedback processing</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1371/journal.pcbi.1005684">[Paper] </a><a target="_blank" rel="noopener" href="https://doi.org/10.6084/m9.figshare.4265408.v1"> [Data]</a></div><div class="post-content"><p>Previous studies suggest that factual learning, that is, learning from obtained outcomes, is biased, such that participants preferentially take into account positive, as compared to negative, prediction errors. However, whether or not the prediction error valence also affects counterfactual learning, that is, learning from forgone outcomes, is unknown. To address this question, we analysed the performance of two groups of participants on reinforcement learning tasks using a computational model that was adapted to test if prediction error valence influences learning. We...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/2-arm-bandit/" title="2-arm bandit">2-arm bandit </a><a class="tag" href="/opendata/tags/counterfactual-feedback/" title="counterfactual feedback">counterfactual feedback </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/klein-et-al-2017/">Klein et al. (2017)</a></h3></div><div class="post-subtitle"><h4>Learning relative values in the striatum induces violations of normative decision making</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1038/ncomms16033">[Paper] </a><a target="_blank" rel="noopener" href="https://www.nature.com/articles/s41467-019-10718-8#Sec19"> [Data]</a></div><div class="post-content"><p>To decide optimally between available options, organisms need to learn the values associated with these options. Reinforcement learning models offer a powerful explanation of how these values are learnt from experience. However, human choices often violate normative principles. We suggest that seemingly counterintuitive decisions may arise as a natural consequence of the learning mechanisms deployed by humans. Here, using fMRI and a novel behavioural task, we show that, when suddenly switched to novel choice contexts, participants choices are incongruent with values...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/explore-exploit/" title="explore/exploit">explore/exploit </a><a class="tag" href="/opendata/tags/2-arm-bandit/" title="2-arm bandit">2-arm bandit </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/engelmann-et-al-2017/">Engelmann et al. (2017)</a></h3></div><div class="post-subtitle"><h4>Hyper-responsivity to losses in the anterior insula during economic choice scales with depression severity</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1017/S0033291717001428">[Paper] </a><a target="_blank" rel="noopener" href="https://figshare.com/articles/dataset/Behavioral_Data_-_decisions/6791201"> [Data]</a></div><div class="post-content"><p>Commonly observed distortions in decision-making among patients with major depressive disorder (MDD) may emerge from impaired reward processing and cognitive biases toward negative events. There is substantial theoretical support for the hypothesis that MDD patients overweight potential losses compared with gains, though the neurobiological underpinnings of this bias are uncertain. Twenty-one unmedicated patients with MDD were compared with 25 healthy controls (HC) using functional magnetic resonance imaging (fMRI) together with an economic decision-making task over...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/depression/" title="depression">depression </a><a class="tag" href="/opendata/tags/decisions-from-description/" title="decisions from description">decisions from description </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/potter-et-al-2017/">Potter et al. (2017)</a></h3></div><div class="post-subtitle"><h4>Cognitive components underpinning the development of model-based learning</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1016/j.dcn.2016.10.005">[Paper] </a><a target="_blank" rel="noopener" href="https://github.com/hartleylabnyu/online_two_step_replication/tree/master/analysis_code_and_data/data/potter"> [Data]</a></div><div class="post-content"><p>Reinforcement learning theory distinguishes “model-free” learning, which fosters reflexive repetition of previously rewarded actions, from “model-based” learning, which recruits a mental model of the environment to flexibly select goal-directed actions. Whereas model-free learning is evident across development, recruitment of model-based learning appears to increase with age. However, the cognitive processes underlying the development of model-based learning remain poorly characterized. Here, we examined whether age-related differences in cognitive processes underlying...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/development/" title="development">development </a><a class="tag" href="/opendata/tags/adolescence/" title="adolescence">adolescence </a><a class="tag" href="/opendata/tags/working-memory/" title="working memory">working memory </a><a class="tag" href="/opendata/tags/two-step/" title="two-step">two-step </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/swart-et-al-2017/">Swart et al. (2017)</a></h3></div><div class="post-subtitle"><h4>Catecholaminergic challenge uncovers distinct Pavlovian and instrumental mechanisms of motivated (in)action</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.7554/eLife.22169">[Paper] </a><a target="_blank" rel="noopener" href="https://elifesciences.org/articles/22169/figures#SD1-data"> [Data]</a></div><div class="post-content"><p>Catecholamines modulate the impact of motivational cues on action. Such motivational biases have been proposed to reflect cue-based, Pavlovian effects. Here, we assess whether motivational biases may also arise from asymmetrical instrumental learning of active and passive responses following reward and punishment outcomes. We present a novel paradigm, allowing us to disentangle the impact of reward and punishment on instrumental learning from Pavlovian response biasing. Computational analyses showed that motivational biases reflect both Pavlovian and instrumental...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/pavlovian-go-no-go-task/" title="pavlovian go/no-go task">pavlovian go/no-go task </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/warren-et-al-2017/">Warren et al. (2017)</a></h3></div><div class="post-subtitle"><h4>The effect of atomoxetine on random and directed exploration in humans</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1371/journal.pone.0176034">[Paper] </a><a target="_blank" rel="noopener" href="https://doi.org/10.5061/dryad.14m41"> [Data]</a></div><div class="post-content"><p>The adaptive regulation of the trade-off between pursuing a known reward (exploitation) and sampling lesser-known options in search of something better (exploration) is critical for optimal performance. Theory and recent empirical work suggest that humans use at least two strategies for solving this dilemma: a directed strategy in which choices are explicitly biased toward information seeking, and a random strategy in which decision noise leads to exploration by chance. Here we examined the hypothesis that random exploration is governed by the neuromodulatory locus...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/explore-exploit/" title="explore/exploit">explore/exploit </a><a class="tag" href="/opendata/tags/horizons-task/" title="horizons task">horizons task </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/kool-et-al-2017/">Kool et al. (2017)</a></h3></div><div class="post-subtitle"><h4>Cost-Benefit Arbitration Between Multiple Reinforcement-Learning Systems</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1177/0956797617708288">[Paper] </a><a target="_blank" rel="noopener" href="https://osf.io/6z5rs/"> [Data]</a></div><div class="post-content"><p>Human behavior is sometimes determined by habit and other times by goal-directed planning. Modern reinforcement-learning theories formalize this distinction as a competition between a computationally cheap but inaccurate model-free system that gives rise to habits and a computationally expensive but accurate model-based system that implements planning. It is unclear, however, how people choose to allocate control between these systems. Here, we propose that arbitration occurs by comparing each systems task-specific costs and benefits. To investigate this proposal, we...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/two-step/" title="two-step">two-step </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/cavanaugh-et-al-2017/">Cavanaugh et al. (2017)</a></h3></div><div class="post-subtitle"><h4>Cognitive states influence dopamine-driven aberrant learning in Parkinson's disease</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1016/j.cortex.2017.02.021">[Paper] </a><a target="_blank" rel="noopener" href="https://doi.org/10.18112/openneuro.ds003506.v1.1.0"> [Data]</a></div><div class="post-content"><p>Individual differences in dopaminergic tone underlie tendencies to learn from reward versus punishment. These effects are well documented in Parkinsons patients, who vacillate between low and high tonic dopaminergic states as a function of medication. Yet very few studies have investigated the influence of higher-level cognitive states known to affect downstream dopaminergic learning in Parkinsons patients. A dopamine-dependent cognitive influence over learning would provide a candidate mechanism for declining cognitive integrity and motivation in Parkinsons patients....</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/2-arm-bandit/" title="2-arm bandit">2-arm bandit </a><a class="tag" href="/opendata/tags/m-eeg/" title="m/eeg">m/eeg </a><a class="tag" href="/opendata/tags/agency/" title="agency">agency </a><a class="tag" href="/opendata/tags/parkinson-s/" title="parkinson's">parkinson's </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/lefebvre-et-al-2017/">Lefebvre et al. (2017)</a></h3></div><div class="post-subtitle"><h4>Behavioural and neural characterization of optimistic reinforcement learning</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1038/s41562-017-0067">[Paper] </a><a target="_blank" rel="noopener" href="https://figshare.com/articles/dataset/Behavioral_data_and_data_extraction_code/4265408/1"> [Data]</a></div><div class="post-content"><p>When forming and updating beliefs about future life outcomes, people tend to consider good news and to disregard bad news. This tendency is assumed to support the optimism bias. Whether this learning bias is specific to ‘high-level’ abstract belief update or a particular expression of a more general ‘low-level’ reinforcement learning process is unknown. Here we report evidence in favour of the second hypothesis. In a simple instrumental learning task, participants incorporated better-than-expected outcomes at a higher rate than worse-than-expected ones. In addition,...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/2-arm-bandit/" title="2-arm bandit">2-arm bandit </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/urai-et-al-2017/">Urai et al. (2017)</a></h3></div><div class="post-subtitle"><h4>Pupil-linked arousal is driven by decision uncertainty and alters serial choice bias</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1038/ncomms14637">[Paper] </a><a target="_blank" rel="noopener" href="https://doi.org/10.6084/m9.figshare.4300043"> [Data]</a></div><div class="post-content"><p>While judging their sensory environments, decision-makers seem to use the uncertainty about their choices to guide adjustments of their subsequent behaviour. One possible source of these behavioural adjustments is arousal: decision uncertainty might drive the brains arousal systems, which control global brain state and might thereby shape subsequent decision-making. Here, we measure pupil diameter, a proxy for central arousal state, in human observers performing a perceptual choice task of varying difficulty. Pupil dilation, after choice but before external feedback,...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/perceptual-decision-making/" title="perceptual decision making">perceptual decision making </a><a class="tag" href="/opendata/tags/eye-tracking/" title="eye-tracking">eye-tracking </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/erev-et-al-2017/">Erev et al. (2017)</a></h3></div><div class="post-subtitle"><h4>From anomalies to forecasts: Toward a descriptive model of decisions under risk, under ambiguity, and from experience.</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1037/rev0000062">[Paper] </a><a target="_blank" rel="noopener" href="https://zenodo.org/record/845873#.WeDg9GhSw2x"> [Data]</a></div><div class="post-content"><p>Experimental studies of choice behavior document distinct, and sometimes contradictory, deviations from maximization. For example, people tend to overweight rare events in 1-shot decisions under risk, and to exhibit the opposite bias when they rely on past experience. The common explanations of these results assume that the contradicting anomalies reflect situation-specific processes that involve the weighting of subjective values and the use of simple heuristics. The current article analyzes 14 choice anomalies that have been described by different models, including...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/decisions-from-description/" title="decisions from description">decisions from description </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/mkrtchian-et-al-2017/">Mkrtchian et al. (2017)</a></h3></div><div class="post-subtitle"><h4>Modeling Avoidance in Mood and Anxiety Disorders Using Reinforcement Learning</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1016/j.biopsych.2017.01.017">[Paper] </a><a target="_blank" rel="noopener" href="https://figshare.com/articles/Avoidance_Anxiety_Materials/3860250"> [Data]</a></div><div class="post-content"><p>Serious and debilitating symptoms of anxiety are the most common mental health problem worldwide, accounting for around 5% of all adult years lived with disability in the developed world. Avoidance behavior-avoiding social situations for fear of embarrassment, for instance-is a core feature of such anxiety. However, as for many other psychiatric symptoms the biological mechanisms underlying avoidance remain unclear. Reinforcement learning models provide formal and testable characterizations of the mechanisms of decision making; here, we examine avoidance in these terms....</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/pavlovian-go-no-go-task/" title="pavlovian go/no-go task">pavlovian go/no-go task </a><a class="tag" href="/opendata/tags/anxiety/" title="anxiety">anxiety </a><a class="tag" href="/opendata/tags/depression/" title="depression">depression </a></div></div></div></div><div class="pagination"><ul class="clearfix"><li class="pre pagbuttons"><a class="btn" role="navigation" href="/opendata/page/6/">Previous</a></li><li class="next pagbuttons"><a class="btn" role="navigation" href="/opendata/page/8/">Next</a></li></ul></div></div></div></div><script src="/opendata/js/jquery-migrate-1.2.1.min.js"></script><script src="/opendata/js/jquery.appear.js"></script><script src="/opendata/js/add-bookmark.js"></script><script>(function(window){var INSIGHT_CONFIG={TRANSLATION:{POSTS:"Posts",PAGES:"Pages",CATEGORIES:"Categories",TAGS:"Tags",UNTITLED:"(Untitled)",},CONTENT_URL:"/opendata/content.json",};window.INSIGHT_CONFIG=INSIGHT_CONFIG})(window);</script><script src="/opendata/js/insight.js" defer></script><div class="searchbox ins-search"><div class="searchbox-container ins-search-container"><div class="searchbox-input-wrapper"><input class="searchbox-input ins-search-input" type="text" placeholder="Search..."><span class="searchbox-close"><a class="fa fa-times-circle" onclick="closeWindow();"></a></span></div><div class="searchbox-result-wrapper ins-section-wrapper"><div class="ins-section-container"><p>Seraching...</p></div></div></div></div></body></html>