<!DOCTYPE html><html lang="zh-CN"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta name="author" content="DSST/NIMH"><title>OpenData</title><meta name="description" content="A collection of publicly available&lt;br&gt;behavioral datasets"><meta name="keywords"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="renderer" content="webkit"><link rel="shortcut icon" type="image/x-icon" href="/images/favicon.webp"><link rel="stylesheet" href="/opendata/css/style.css"><link rel="stylesheet" href="/opendata/css/blog_basic.css"><link rel="stylesheet" href="/opendata/css/font-awesome.min.css"><link rel="stylesheet" href="/opendata/css/insight.css"><link rel="stylesheet" href="/opendata/css/search.css"><link rel="alternate" type="application/atom+xml" title="ATOM 1.0" href="/atom.xml"><script src="/opendata/js/jquery.js"></script><!-- Global site tag (gtag.js) - Google Analytics--><script async src="https://www.googletagmanager.com/gtag/js?id=G-PTJE4Z001J"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-PTJE4Z001J');</script><meta name="generator" content="Hexo 6.3.0"></head><body><div class="page-top animated fadeInDown"><div class="nav"><li><a href="/opendata">Home</a></li><li><a href="/opendata/archives">Archives</a></li><li><a href="/opendata/tags">Tags</a></li><li><a href="/opendata/about">About</a></li><li><a href="/opendata/contribute">Contribute</a></li></div><div class="information"><div class="nav_right_btn"><li><a class="fa fa-chevron-left" onclick="window.history.go(-1)" style="display:none;"></a></li><li><a class="fa fa-search" onclick="openWindow();"></a></li></div><div class="avatar"><img src="/opendata/images/logo.webp" alt="favicon"></div></div></div><div class="sidebar animated fadeInDown"><div class="sidebar-top"><div class="logo-title"><div class="title"><img src="/opendata/images/logo.webp" style="width:175px;" alt="favicon"><h3 title=""><a href="/opendata">OpenData</a></h3><div class="description"><p>A collection of publicly available<br>behavioral datasets</p></div></div><ul class="social-links"><li><a target="_blank" rel="noopener" href="https://github.com/nimh-dsst/opendata"><i class="fa fa-github"></i></a></li></ul></div></div><div class="footer"><div class="p"> <span> MIT License </span><i class="fa fa-star"></i><span> DSST/NIMH</span></div><div class="by_farbox"><span>Powered by </span><a href="https://hexo.io/zh-cn/" target="_blank">Hexo </a><span> & </span><span>Anatolo </span></div><div class="beian"></div></div></div><div class="main"><div class="autopagerize_page_element"><div class="content"><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/correa-et-al-2018/">Correa et al. (2018)</a></h3></div><div class="post-subtitle"><h4>How the Level of Reward Awareness Changes the Computational and Electrophysiological Signatures of Reinforcement Learning</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1523/JNEUROSCI.0457-18.2018">[Paper] </a><a target="_blank" rel="noopener" href="https://figshare.com/articles/Codes_and_Data_-_Correa_et_al_JNeuro_2018/7987100"> [Data]</a></div><div class="post-content"><p>The extent to which subjective awareness influences reward processing, and thereby affects future decisions, is currently largely unknown. In the present report, we investigated this question in a reinforcement learning framework, combining perceptual masking, computational modeling, and electroencephalographic recordings (human male and female participants). Our results indicate that degrading the visibility of the reward decreased, without completely obliterating, the ability of participants to learn from outcomes, but concurrently increased their tendency to repeat...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/2-arm-bandit/" title="2-arm bandit">2-arm bandit </a><a class="tag" href="/opendata/tags/reversal-learning/" title="reversal learning">reversal learning </a><a class="tag" href="/opendata/tags/reward-visibility/" title="reward visibility">reward visibility </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/braun-et-al-2018/">Braun et al. (2018)</a></h3></div><div class="post-subtitle"><h4>Retroactive and graded prioritization of memory by reward</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1038/s41467-018-07280-0">[Paper] </a><a target="_blank" rel="noopener" href="https://osf.io/gz9xe/"> [Data]</a></div><div class="post-content"><p>Many decisions are based on an internal model of the world. Yet, how such a model is constructed from experience and represented in memory remains unknown. We test the hypothesis that reward shapes memory for sequences of events by retroactively prioritizing memory for objects as a function of their distance from reward. Human participants encountered neutral objects while exploring a series of mazes for reward. Across six data sets, we find that reward systematically modulates memory for neutral objects, retroactively prioritizing memory for objects closest to the...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/memory/" title="memory">memory </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/lockwood-et-al-2018/">Lockwood et al. (2018)</a></h3></div><div class="post-subtitle"><h4>Neural mechanisms for learning self and other ownership</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1038/s41467-018-07231-9">[Paper] </a><a target="_blank" rel="noopener" href="https://doi.org/10.17605/OSF.IO/NWUZ8"> [Data]</a></div><div class="post-content"><p>Sense of ownership is a ubiquitous and fundamental aspect of human cognition. Here we used model-based functional magnetic resonance imaging and a novel minimal ownership paradigm to probe the behavioural and neural mechanisms underpinning ownership acquisition for ourselves, friends and strangers. We find a self-ownership bias at multiple levels of behaviour from initial preferences to reaction times and computational learning rates. Ventromedial prefrontal cortex (vmPFC) and anterior cingulate sulcus (ACCs) responded more to self vs. stranger associations, but despite...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/wu-et-al-2018/">Wu et al. (2018)</a></h3></div><div class="post-subtitle"><h4>Generalization guides human exploration in vast decision spaces</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1038/s41562-018-0467-4">[Paper] </a><a target="_blank" rel="noopener" href="https://github.com/charleywu/gridsearch"> [Data]</a></div><div class="post-content"><p>From foraging for food to learning complex games, many aspects of human behaviour can be framed as a search problem with a vast space of possible actions. Under finite search horizons, optimal solutions are generally unobtainable. Yet, how do humans navigate vast problem spaces, which require intelligent exploration of unobserved actions? Using various bandit tasks with up to 121 arms, we study how humans search for rewards under limited search horizons, in which the spatial correlation of rewards (in both generated and natural environments) provides traction for...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/sequential-decision-making/" title="sequential decision making">sequential decision making </a><a class="tag" href="/opendata/tags/continuous-outcomes/" title="continuous outcomes">continuous outcomes </a><a class="tag" href="/opendata/tags/generalization/" title="generalization">generalization </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/konstantinidis-et-al-2018/">Konstantinidis et al. (2018)</a></h3></div><div class="post-subtitle"><h4>Magnitude and incentives: revisiting the overweighting of extreme events in risky decisions from experience</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.3758/s13423-017-1383-8">[Paper] </a><a target="_blank" rel="noopener" href="https://osf.io/z57tn/"> [Data]</a></div><div class="post-content"><p>Recent experimental evidence in experience-based decision-making suggests that people are more risk seeking in the gains domain relative to the losses domain. This critical result is at odds with the standard reflection effect observed in description-based choice and explained by Prospect Theory. The so-called reversed-reflection effect has been predicated on the extreme-outcome rule, which suggests that memory biases affect risky choice from experience. To test the general plausibility of the rule, we conducted two experiments examining how the magnitude of prospective...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/2-arm-bandit/" title="2-arm bandit">2-arm bandit </a><a class="tag" href="/opendata/tags/risk-sensitivity/" title="risk sensitivity">risk sensitivity </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/bavard-et-al-2018/">Bavard et al. (2018)</a></h3></div><div class="post-subtitle"><h4>Reference-point centering and range-adaptation enhance human reinforcement learning at the cost of irrational preferences</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1038/s41467-018-06781-2">[Paper] </a><a target="_blank" rel="noopener" href="https://github.com/sophiebavard/Magnitude"> [Data]</a></div><div class="post-content"><p>In economics and perceptual decision-making contextual effects are well documented, where decision weights are adjusted as a function of the distribution of stimuli. Yet, in reinforcement learning literature whether and how contextual information pertaining to decision states is integrated in learning algorithms has received comparably little attention. Here, we investigate reinforcement learning behavior and its computational substrates in a task where we orthogonally manipulate outcome valence and magnitude, resulting in systematic variations in state-values. Model...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/2-arm-bandit/" title="2-arm bandit">2-arm bandit </a><a class="tag" href="/opendata/tags/range-adaptation/" title="range adaptation">range adaptation </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/swart-et-al-2018/">Swart et al. (2018)</a></h3></div><div class="post-subtitle"><h4>Frontal network dynamics reflect neurocomputational mechanisms for reducing maladaptive biases in motivated action</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1371/journal.pbio.2005979">[Paper] </a><a target="_blank" rel="noopener" href="https://data.donders.ru.nl/collections/di/dccn/DSC_3017033.03_624?0"> [Data]</a></div><div class="post-content"><p>Motivation exerts control over behavior by eliciting Pavlovian responses, which can either match or conflict with instrumental action. We can overcome maladaptive motivational influences putatively through frontal cognitive control. However, the neurocomputational mechanisms subserving this control are unclear; does control entail up-regulating instrumental systems, down-regulating Pavlovian systems, or both? We combined electroencephalography (EEG) recordings with a motivational Go&#x2F;NoGo learning task (N &#x3D; 34), in which multiple Go options enabled us to...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/pavlovian-go-no-go-task/" title="pavlovian go/no-go task">pavlovian go/no-go task </a><a class="tag" href="/opendata/tags/m-eeg/" title="m/eeg">m/eeg </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/collins-2018/">Collins (2018)</a></h3></div><div class="post-subtitle"><h4>The Tortoise and the Hare: Interactions between Reinforcement Learning and Working Memory</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1162/jocn_a_01238">[Paper] </a><a target="_blank" rel="noopener" href="https://osf.io/5gbr3/"> [Data]</a></div><div class="post-content"><p>Learning to make rewarding choices in response to stimuli depends on a slow but steady process, reinforcement learning, and a fast and flexible, but capacity-limited process, working memory. Using both systems in parallel, with their contributions weighted based on performance, should allow us to leverage the best of each system: rapid early learning, supplemented by long-term robust acquisition. However, this assumes that using one process does not interfere with the other. We use computational modeling to investigate the interactions between the two processes in a...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/working-memory/" title="working memory">working memory </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/kool-et-al-2018/">Kool et al. (2018)</a></h3></div><div class="post-subtitle"><h4>Planning complexity registers as a cost in metacontrol</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1162/jocn_a_01263">[Paper] </a><a target="_blank" rel="noopener" href="https://osf.io/793yw/"> [Data]</a></div><div class="post-content"><p>Decision-making algorithms face a basic tradeoff between accuracy and effort (i.e., computational demands). It is widely agreed that humans can choose between multiple decision-making processes that embody different solutions to this tradeoff: Some are computationally cheap but inaccurate, whereas others are computationally expensive but accurate. Recent progress in understanding this tradeoff has been catalyzed by formalizing it in terms of model-free (i.e., habitual) versus model-based (i.e., planning) approaches to reinforcement learning. Intuitively, if two tasks...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/sequential-decision-making/" title="sequential decision making">sequential decision making </a><a class="tag" href="/opendata/tags/two-step/" title="two-step">two-step </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/millner-et-al-2018/">Millner et al. (2018)</a></h3></div><div class="post-subtitle"><h4>Pavlovian Control of Escape and Avoidance</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1162/jocn_a_01224">[Paper] </a><a target="_blank" rel="noopener" href="https://osf.io/p36u5/"> [Data]</a></div><div class="post-content"><p>To survive in complex environments, animals need to have mechanisms to select effective actions quickly, with minimal computational costs. As perhaps the computationally most parsimonious of these systems, Pavlovian control accomplishes this by hardwiring specific stereotyped responses to certain classes of stimuli. It is well documented that appetitive cues initiate a Pavlovian bias toward vigorous approach; however, Pavlovian responses to aversive stimuli are less well understood. Gaining a deeper understanding of aversive Pavlovian responses, such as active...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/pavlovian-go-no-go-task/" title="pavlovian go/no-go task">pavlovian go/no-go task </a><a class="tag" href="/opendata/tags/avoidance/" title="avoidance">avoidance </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/wimmer-et-al-2018/">Wimmer et al. (2018)</a></h3></div><div class="post-subtitle"><h4>Reward learning over weeks versus minutes increases the neural representation of value in the human brain</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1523/JNEUROSCI.0075-18.2018">[Paper] </a><a target="_blank" rel="noopener" href="https://osf.io/z2gwf/"> [Data]</a></div><div class="post-content"><p>Over the past few decades, neuroscience research has illuminated the neural mechanisms supporting learning from reward feedback. Learning paradigms are increasingly being extended to study mood and psychiatric disorders as well as addiction. However, one potentially critical characteristic that this research ignores is the effect of time on learning: human feedback learning paradigms are usually conducted in a single rapidly paced session, whereas learning experiences in ecologically relevant circumstances and in animal research are almost always separated by longer...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/memory/" title="memory">memory </a><a class="tag" href="/opendata/tags/2-arm-bandit/" title="2-arm bandit">2-arm bandit </a><a class="tag" href="/opendata/tags/working-memory/" title="working memory">working memory </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/navarro-et-al-2018/">Navarro et al. (2018)</a></h3></div><div class="post-subtitle"><h4>Aversion to option loss in a restless bandit task</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1007/s42113-018-0010-8">[Paper] </a><a target="_blank" rel="noopener" href="https://osf.io/nzvqp/"> [Data]</a></div><div class="post-content"><p>In everyday life, people need to make choices without full information about the environment, which poses an explore-exploit dilemma in which one must balance the need to learn about the world and the need to obtain rewards from it. The explore-exploit dilemma is often studied using the multi-armed restless bandit task, in which people repeatedly select from multiple options, and human behaviour is modelled as a form of reinforcement learning via Kalman filters. Inspired by work in the judgment and decision-making literature, we present two experiments using multi-armed...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/explore-exploit/" title="explore/exploit">explore/exploit </a><a class="tag" href="/opendata/tags/multi-arm-bandit/" title="multi-arm bandit">multi-arm bandit </a><a class="tag" href="/opendata/tags/restless-bandit/" title="restless bandit">restless bandit </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/polti-et-al-2018/">Polti et al. (2018)</a></h3></div><div class="post-subtitle"><h4>The effect of attention and working memory on the estimation of elapsed time</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1038/s41598-018-25119-y">[Paper] </a><a target="_blank" rel="noopener" href="https://osf.io/cg7ex/"> [Data]</a></div><div class="post-content"><p>Psychological models of time perception involve attention and memory: while attention typically regulates the flow of events, memory maintains timed events or intervals. The precise, and possibly distinct, roles of attention and memory in time perception remain debated. In this behavioral study, we tested 48 participants in a prospective duration estimation task while they fully attended to time or performed a working memory (WM) task. We report that paying attention to time lengthened perceived duration in the range of seconds to minutes, whereas diverting attention...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/rouhani-et-al-2018/">Rouhani et al. (2018)</a></h3></div><div class="post-subtitle"><h4>Dissociable effects of surprising rewards on learning and memory</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1037/xlm0000518">[Paper] </a><a target="_blank" rel="noopener" href="https://nivlab.princeton.edu/sites/default/files/nivlab/files/rouhani2018_inddiff_allexps.csv"> [Data]</a></div><div class="post-content"><p>Reward-prediction errors track the extent to which rewards deviate from expectations, and aid in learning. How do such errors in prediction interact with memory for the rewarding episode? Existing findings point to both cooperative and competitive interactions between learning and memory mechanisms. Here, we investigated whether learning about rewards in a high-risk context, with frequent, large prediction errors, would give rise to higher fidelity memory traces for rewarding events than learning in a low-risk context. Experiment 1 showed that recognition was better for...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/memory/" title="memory">memory </a><a class="tag" href="/opendata/tags/continuous-outcomes/" title="continuous outcomes">continuous outcomes </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/corcoran-et-al-2018/">Corcoran et al. (2018)</a></h3></div><div class="post-subtitle"><h4>Individual differences in first- and second-order temporal judgment</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1371/journal.pone.0191422">[Paper] </a><a target="_blank" rel="noopener" href="https://doi.org/10.1371/journal.pone.0191422.s002"> [Data]</a></div><div class="post-content"><p>The ability of subjects to identify and reproduce brief temporal intervals is influenced by many factors whether they be stimulus-based, task-based or subject-based. The current study examines the role individual differences play in subsecond and suprasecond timing judgments, using the schizoptypy personality scale as a test-case approach for quantifying a broad range of individual differences. In two experiments, 129 (Experiment 1) and 141 (Experiment 2) subjects completed the O-LIFE personality questionnaire prior to performing a modified temporal-bisection task. In...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/pachur-et-al-2018/">Pachur et al. (2018)</a></h3></div><div class="post-subtitle"><h4>Prospect theory reflects selective allocation of attention.</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1037/xge0000406">[Paper] </a><a target="_blank" rel="noopener" href="https://osf.io/5semf/"> [Data]</a></div><div class="post-content"><p>There is a disconnect in the literature between analyses of risky choice based on cumulative prospect theory (CPT) and work on predecisional information processing. One likely reason is that for expectation models (e.g., CPT), it is often assumed that people behaved only as if they conducted the computations leading to the predicted choice and that the models are thus mute regarding information processing. We suggest that key psychological constructs in CPT, such as loss aversion and outcome and probability sensitivity, can be interpreted in terms of attention...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/risk-sensitivity/" title="risk sensitivity">risk sensitivity </a><a class="tag" href="/opendata/tags/decisions-from-description/" title="decisions from description">decisions from description </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/khaw-et-al-2017/">Khaw et al. (2017)</a></h3></div><div class="post-subtitle"><h4>Forecasting the outcome of a time-varying Bernoulli process: Data from a laboratory experiment</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1016/j.dib.2017.10.007">[Paper] </a><a target="_blank" rel="noopener" href="https://doi.org/10.1016/j.dib.2017.10.007"> [Data]</a></div><div class="post-content"><p>The data presented in this article are related to the research article entitled “Discrete Adjustment to a Changing Environment: Experimental Evidence” (Khaw et al., 2017) [1]. We present data from a laboratory experiment that asks subjects to forecast the outcome of a time-varying Bernoulli process. On a computer program, subjects draw rings with replacement from a virtual box containing green and red rings in an unknown proportion. Subjects provide their estimates of the probability of drawing a green ring. They are rewarded for their participation and for the accuracy...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/tarantola-et-al-2017/">Tarantola et al. (2017)</a></h3></div><div class="post-subtitle"><h4>Prior preferences beneficially influence social and non-social learning</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1038/s41467-017-00826-8">[Paper] </a><a target="_blank" rel="noopener" href="https://figshare.com/articles/dataset/Prior_preferences_beneficially_influence_social_and_non-social_learning/5198572"> [Data]</a></div><div class="post-content"><p>Our personal preferences affect a broad array of social behaviors. This includes the way we learn the preferences of others, an ability that often relies on limited or ambiguous information. Here we report an egocentric influence on this type of social learning that is reflected in both performance and response times. Using computational models that combine inter-trial learning and intra-trial choice, we find transient effects of participants preferences on the learning process, through the influence of priors, and persistent effects on the choice process. A second...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/2-arm-bandit/" title="2-arm bandit">2-arm bandit </a><a class="tag" href="/opendata/tags/social-decision-making/" title="social decision making">social decision making </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/frey-et-al-2017/">Frey et al. (2017)</a></h3></div><div class="post-subtitle"><h4>Risk preference shares the psychometric structure of major psychological traits</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1126/sciadv.1701381">[Paper] </a><a target="_blank" rel="noopener" href="https://osf.io/rce7g/"> [Data]</a></div><div class="post-content"><p>To what extent is there a general factor of risk preference, R, akin to g, the general factor of intelligence? Can risk preference be regarded as a stable psychological trait? These conceptual issues persist because few attempts have been made to integrate multiple risk-taking measures, particularly measures from different and largely unrelated measurement traditions (self-reported propensity measures assessing stated preferences, incentivized behavioral measures eliciting revealed preferences, and frequency measures assessing actual risky activities). Adopting a...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/sequential-decision-making/" title="sequential decision making">sequential decision making </a><a class="tag" href="/opendata/tags/risk-sensitivity/" title="risk sensitivity">risk sensitivity </a><a class="tag" href="/opendata/tags/test-retest/" title="test-retest">test-retest </a><a class="tag" href="/opendata/tags/decisions-from-description/" title="decisions from description">decisions from description </a><a class="tag" href="/opendata/tags/balloon-analog-risk-task/" title="balloon analog risk task">balloon analog risk task </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/zajkowski-et-al-2017/">Zajkowski et al. (2017)</a></h3></div><div class="post-subtitle"><h4>A causal role for right frontopolar cortex in directed, but not random, exploration</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.7554/eLife.27430">[Paper] </a><a target="_blank" rel="noopener" href="https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/CZT6EE"> [Data]</a></div><div class="post-content"><p>The explore-exploit dilemma occurs anytime we must choose between exploring unknown options for information and exploiting known resources for reward. Previous work suggests that people use two different strategies to solve the explore-exploit dilemma: directed exploration, driven by information seeking, and random exploration, driven by decision noise. Here, we show that these two strategies rely on different neural systems. Using transcranial magnetic stimulation to inhibit the right frontopolar cortex, we were able to selectively inhibit directed exploration while...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/explore-exploit/" title="explore/exploit">explore/exploit </a><a class="tag" href="/opendata/tags/horizons-task/" title="horizons task">horizons task </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/palminteri-et-al-2017/">Palminteri et al. (2017)</a></h3></div><div class="post-subtitle"><h4>Confirmation bias in human reinforcement learning: Evidence from counterfactual feedback processing</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1371/journal.pcbi.1005684">[Paper] </a><a target="_blank" rel="noopener" href="https://doi.org/10.6084/m9.figshare.4265408.v1"> [Data]</a></div><div class="post-content"><p>Previous studies suggest that factual learning, that is, learning from obtained outcomes, is biased, such that participants preferentially take into account positive, as compared to negative, prediction errors. However, whether or not the prediction error valence also affects counterfactual learning, that is, learning from forgone outcomes, is unknown. To address this question, we analysed the performance of two groups of participants on reinforcement learning tasks using a computational model that was adapted to test if prediction error valence influences learning. We...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/2-arm-bandit/" title="2-arm bandit">2-arm bandit </a><a class="tag" href="/opendata/tags/counterfactual-feedback/" title="counterfactual feedback">counterfactual feedback </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/klein-et-al-2017/">Klein et al. (2017)</a></h3></div><div class="post-subtitle"><h4>Learning relative values in the striatum induces violations of normative decision making</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1038/ncomms16033">[Paper] </a><a target="_blank" rel="noopener" href="https://www.nature.com/articles/s41467-019-10718-8#Sec19"> [Data]</a></div><div class="post-content"><p>To decide optimally between available options, organisms need to learn the values associated with these options. Reinforcement learning models offer a powerful explanation of how these values are learnt from experience. However, human choices often violate normative principles. We suggest that seemingly counterintuitive decisions may arise as a natural consequence of the learning mechanisms deployed by humans. Here, using fMRI and a novel behavioural task, we show that, when suddenly switched to novel choice contexts, participants choices are incongruent with values...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/explore-exploit/" title="explore/exploit">explore/exploit </a><a class="tag" href="/opendata/tags/2-arm-bandit/" title="2-arm bandit">2-arm bandit </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/engelmann-et-al-2017/">Engelmann et al. (2017)</a></h3></div><div class="post-subtitle"><h4>Hyper-responsivity to losses in the anterior insula during economic choice scales with depression severity</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1017/S0033291717001428">[Paper] </a><a target="_blank" rel="noopener" href="https://figshare.com/articles/dataset/Behavioral_Data_-_decisions/6791201"> [Data]</a></div><div class="post-content"><p>Commonly observed distortions in decision-making among patients with major depressive disorder (MDD) may emerge from impaired reward processing and cognitive biases toward negative events. There is substantial theoretical support for the hypothesis that MDD patients overweight potential losses compared with gains, though the neurobiological underpinnings of this bias are uncertain. Twenty-one unmedicated patients with MDD were compared with 25 healthy controls (HC) using functional magnetic resonance imaging (fMRI) together with an economic decision-making task over...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/depression/" title="depression">depression </a><a class="tag" href="/opendata/tags/decisions-from-description/" title="decisions from description">decisions from description </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/potter-et-al-2017/">Potter et al. (2017)</a></h3></div><div class="post-subtitle"><h4>Cognitive components underpinning the development of model-based learning</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1016/j.dcn.2016.10.005">[Paper] </a><a target="_blank" rel="noopener" href="https://github.com/hartleylabnyu/online_two_step_replication/tree/master/analysis_code_and_data/data/potter"> [Data]</a></div><div class="post-content"><p>Reinforcement learning theory distinguishes “model-free” learning, which fosters reflexive repetition of previously rewarded actions, from “model-based” learning, which recruits a mental model of the environment to flexibly select goal-directed actions. Whereas model-free learning is evident across development, recruitment of model-based learning appears to increase with age. However, the cognitive processes underlying the development of model-based learning remain poorly characterized. Here, we examined whether age-related differences in cognitive processes underlying...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/working-memory/" title="working memory">working memory </a><a class="tag" href="/opendata/tags/development/" title="development">development </a><a class="tag" href="/opendata/tags/adolescence/" title="adolescence">adolescence </a><a class="tag" href="/opendata/tags/two-step/" title="two-step">two-step </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/swart-et-al-2017/">Swart et al. (2017)</a></h3></div><div class="post-subtitle"><h4>Catecholaminergic challenge uncovers distinct Pavlovian and instrumental mechanisms of motivated (in)action</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.7554/eLife.22169">[Paper] </a><a target="_blank" rel="noopener" href="https://elifesciences.org/articles/22169/figures#SD1-data"> [Data]</a></div><div class="post-content"><p>Catecholamines modulate the impact of motivational cues on action. Such motivational biases have been proposed to reflect cue-based, Pavlovian effects. Here, we assess whether motivational biases may also arise from asymmetrical instrumental learning of active and passive responses following reward and punishment outcomes. We present a novel paradigm, allowing us to disentangle the impact of reward and punishment on instrumental learning from Pavlovian response biasing. Computational analyses showed that motivational biases reflect both Pavlovian and instrumental...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/pavlovian-go-no-go-task/" title="pavlovian go/no-go task">pavlovian go/no-go task </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/warren-et-al-2017/">Warren et al. (2017)</a></h3></div><div class="post-subtitle"><h4>The effect of atomoxetine on random and directed exploration in humans</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1371/journal.pone.0176034">[Paper] </a><a target="_blank" rel="noopener" href="https://doi.org/10.5061/dryad.14m41"> [Data]</a></div><div class="post-content"><p>The adaptive regulation of the trade-off between pursuing a known reward (exploitation) and sampling lesser-known options in search of something better (exploration) is critical for optimal performance. Theory and recent empirical work suggest that humans use at least two strategies for solving this dilemma: a directed strategy in which choices are explicitly biased toward information seeking, and a random strategy in which decision noise leads to exploration by chance. Here we examined the hypothesis that random exploration is governed by the neuromodulatory locus...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/explore-exploit/" title="explore/exploit">explore/exploit </a><a class="tag" href="/opendata/tags/horizons-task/" title="horizons task">horizons task </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/kool-et-al-2017/">Kool et al. (2017)</a></h3></div><div class="post-subtitle"><h4>Cost-Benefit Arbitration Between Multiple Reinforcement-Learning Systems</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1177/0956797617708288">[Paper] </a><a target="_blank" rel="noopener" href="https://osf.io/6z5rs/"> [Data]</a></div><div class="post-content"><p>Human behavior is sometimes determined by habit and other times by goal-directed planning. Modern reinforcement-learning theories formalize this distinction as a competition between a computationally cheap but inaccurate model-free system that gives rise to habits and a computationally expensive but accurate model-based system that implements planning. It is unclear, however, how people choose to allocate control between these systems. Here, we propose that arbitration occurs by comparing each systems task-specific costs and benefits. To investigate this proposal, we...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/two-step/" title="two-step">two-step </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/cavanaugh-et-al-2017/">Cavanaugh et al. (2017)</a></h3></div><div class="post-subtitle"><h4>Cognitive states influence dopamine-driven aberrant learning in Parkinson's disease</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1016/j.cortex.2017.02.021">[Paper] </a><a target="_blank" rel="noopener" href="https://doi.org/10.18112/openneuro.ds003506.v1.1.0"> [Data]</a></div><div class="post-content"><p>Individual differences in dopaminergic tone underlie tendencies to learn from reward versus punishment. These effects are well documented in Parkinsons patients, who vacillate between low and high tonic dopaminergic states as a function of medication. Yet very few studies have investigated the influence of higher-level cognitive states known to affect downstream dopaminergic learning in Parkinsons patients. A dopamine-dependent cognitive influence over learning would provide a candidate mechanism for declining cognitive integrity and motivation in Parkinsons patients....</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/2-arm-bandit/" title="2-arm bandit">2-arm bandit </a><a class="tag" href="/opendata/tags/m-eeg/" title="m/eeg">m/eeg </a><a class="tag" href="/opendata/tags/agency/" title="agency">agency </a><a class="tag" href="/opendata/tags/parkinson-s/" title="parkinson's">parkinson's </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/lefebvre-et-al-2017/">Lefebvre et al. (2017)</a></h3></div><div class="post-subtitle"><h4>Behavioural and neural characterization of optimistic reinforcement learning</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1038/s41562-017-0067">[Paper] </a><a target="_blank" rel="noopener" href="https://figshare.com/articles/dataset/Behavioral_data_and_data_extraction_code/4265408/1"> [Data]</a></div><div class="post-content"><p>When forming and updating beliefs about future life outcomes, people tend to consider good news and to disregard bad news. This tendency is assumed to support the optimism bias. Whether this learning bias is specific to ‘high-level’ abstract belief update or a particular expression of a more general ‘low-level’ reinforcement learning process is unknown. Here we report evidence in favour of the second hypothesis. In a simple instrumental learning task, participants incorporated better-than-expected outcomes at a higher rate than worse-than-expected ones. In addition,...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/2-arm-bandit/" title="2-arm bandit">2-arm bandit </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/urai-et-al-2017/">Urai et al. (2017)</a></h3></div><div class="post-subtitle"><h4>Pupil-linked arousal is driven by decision uncertainty and alters serial choice bias</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1038/ncomms14637">[Paper] </a><a target="_blank" rel="noopener" href="https://doi.org/10.6084/m9.figshare.4300043"> [Data]</a></div><div class="post-content"><p>While judging their sensory environments, decision-makers seem to use the uncertainty about their choices to guide adjustments of their subsequent behaviour. One possible source of these behavioural adjustments is arousal: decision uncertainty might drive the brains arousal systems, which control global brain state and might thereby shape subsequent decision-making. Here, we measure pupil diameter, a proxy for central arousal state, in human observers performing a perceptual choice task of varying difficulty. Pupil dilation, after choice but before external feedback,...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/perceptual-decision-making/" title="perceptual decision making">perceptual decision making </a><a class="tag" href="/opendata/tags/eye-tracking/" title="eye-tracking">eye-tracking </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/erev-et-al-2017/">Erev et al. (2017)</a></h3></div><div class="post-subtitle"><h4>From anomalies to forecasts: Toward a descriptive model of decisions under risk, under ambiguity, and from experience.</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1037/rev0000062">[Paper] </a><a target="_blank" rel="noopener" href="https://zenodo.org/record/845873#.WeDg9GhSw2x"> [Data]</a></div><div class="post-content"><p>Experimental studies of choice behavior document distinct, and sometimes contradictory, deviations from maximization. For example, people tend to overweight rare events in 1-shot decisions under risk, and to exhibit the opposite bias when they rely on past experience. The common explanations of these results assume that the contradicting anomalies reflect situation-specific processes that involve the weighting of subjective values and the use of simple heuristics. The current article analyzes 14 choice anomalies that have been described by different models, including...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/decisions-from-description/" title="decisions from description">decisions from description </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/mkrtchian-et-al-2017/">Mkrtchian et al. (2017)</a></h3></div><div class="post-subtitle"><h4>Modeling Avoidance in Mood and Anxiety Disorders Using Reinforcement Learning</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1016/j.biopsych.2017.01.017">[Paper] </a><a target="_blank" rel="noopener" href="https://figshare.com/articles/Avoidance_Anxiety_Materials/3860250"> [Data]</a></div><div class="post-content"><p>Serious and debilitating symptoms of anxiety are the most common mental health problem worldwide, accounting for around 5% of all adult years lived with disability in the developed world. Avoidance behavior-avoiding social situations for fear of embarrassment, for instance-is a core feature of such anxiety. However, as for many other psychiatric symptoms the biological mechanisms underlying avoidance remain unclear. Reinforcement learning models provide formal and testable characterizations of the mechanisms of decision making; here, we examine avoidance in these terms....</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/pavlovian-go-no-go-task/" title="pavlovian go/no-go task">pavlovian go/no-go task </a><a class="tag" href="/opendata/tags/anxiety/" title="anxiety">anxiety </a><a class="tag" href="/opendata/tags/depression/" title="depression">depression </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/pachur-et-al-2017/">Pachur et al. (2017)</a></h3></div><div class="post-subtitle"><h4>Who Dares, Who Errs? Disentangling Cognitive and Motivational Roots of Age Differences in Decisions Under Risk</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1177/0956797616687729">[Paper] </a><a target="_blank" rel="noopener" href="https://osf.io/35pf6/"> [Data]</a></div><div class="post-content"><p>We separate for the first time the roles of cognitive and motivational factors in shaping age differences in decision making under risk. Younger and older adults completed gain, loss, and mixed-domain choice problems as well as measures of cognitive functioning and affect. The older adults decision quality was lower than the younger adults in the loss domain, and this age difference was attributable to the older adults lower cognitive abilities. In addition, the older adults chose the more risky option more often than the younger adults in the gain and mixed domains;...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/risk-sensitivity/" title="risk sensitivity">risk sensitivity </a><a class="tag" href="/opendata/tags/development/" title="development">development </a><a class="tag" href="/opendata/tags/decisions-from-description/" title="decisions from description">decisions from description </a><a class="tag" href="/opendata/tags/aging/" title="aging">aging </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/turi-et-al-2017/">Turi et al. (2017)</a></h3></div><div class="post-subtitle"><h4>Placebo Intervention Enhances Reward Learning in Healthy Individuals</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1038/srep41028">[Paper] </a><a target="_blank" rel="noopener" href="https://github.com/ihrke/2016-placebo-tdcs-study"> [Data]</a></div><div class="post-content"><p>According to the placebo-reward hypothesis, placebo is a reward-anticipation process that increases midbrain dopamine (DA) levels. Reward-based learning processes, such as reinforcement learning, involves a large part of the DA-ergic network that is also activated by the placebo intervention. Given the neurochemical overlap between placebo and reward learning, we investigated whether verbal instructions in conjunction with a placebo intervention are capable of enhancing reward learning in healthy individuals by using a monetary reward-based reinforcement-learning task....</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/2-arm-bandit/" title="2-arm bandit">2-arm bandit </a><a class="tag" href="/opendata/tags/tdcs/" title="tdcs">tdcs </a><a class="tag" href="/opendata/tags/probabilistic-selection-task/" title="probabilistic selection task">probabilistic selection task </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/palminteri-et-al-2016/">Palminteri et al. (2016)</a></h3></div><div class="post-subtitle"><h4>The Computational Development of Reinforcement Learning during Adolescence</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1371/journal.pcbi.1004953">[Paper] </a><a target="_blank" rel="noopener" href="https://figshare.com/articles/dataset/Behavioural_data_from_adults_and_adolescents_as_well_as_demographics_/3398056/1"> [Data]</a></div><div class="post-content"><p>Adolescence is a period of life characterised by changes in learning and decision-making. Learning and decision-making do not rely on a unitary system, but instead require the coordination of different cognitive processes that can be mathematically formalised as dissociable computational modules. Here, we aimed to trace the developmental time-course of the computational modules responsible for learning from reward or punishment, and learning from counterfactual feedback. Adolescents and adults carried out a novel reinforcement learning paradigm in which participants...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/2-arm-bandit/" title="2-arm bandit">2-arm bandit </a><a class="tag" href="/opendata/tags/development/" title="development">development </a><a class="tag" href="/opendata/tags/adolescence/" title="adolescence">adolescence </a><a class="tag" href="/opendata/tags/counterfactual-feedback/" title="counterfactual feedback">counterfactual feedback </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/decker-et-al-2016/">Decker et al. (2016)</a></h3></div><div class="post-subtitle"><h4>From Creatures of Habit to Goal-Directed Learners: Tracking the Developmental Emergence of Model-Based Reinforcement Learning</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1177/0956797616639301">[Paper] </a><a target="_blank" rel="noopener" href="https://github.com/hartleylabnyu/online_two_step_replication/tree/master/analysis_code_and_data/data/decker"> [Data]</a></div><div class="post-content"><p>Theoretical models distinguish two decision-making strategies that have been formalized in reinforcement-learning theory. A model-based strategy leverages a cognitive model of potential actions and their consequences to make goal-directed choices, whereas a model-free strategy evaluates actions based solely on their reward history. Research in adults has begun to elucidate the psychological mechanisms and neural substrates underlying these learning processes and factors that influence their relative recruitment. However, the developmental trajectory of these evaluative...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/development/" title="development">development </a><a class="tag" href="/opendata/tags/adolescence/" title="adolescence">adolescence </a><a class="tag" href="/opendata/tags/two-step/" title="two-step">two-step </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/albrecht-et-al-2016/">Albrecht et al. (2016)</a></h3></div><div class="post-subtitle"><h4>Reduction of Pavlovian Bias in Schizophrenia: Enhanced Effects in Clozapine-Administered Patients</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1371/journal.pone.0152781">[Paper] </a><a target="_blank" rel="noopener" href="https://zenodo.org/record/29601"> [Data]</a></div><div class="post-content"><p>The negative symptoms of schizophrenia (SZ) are associated with a pattern of reinforcement learning (RL) deficits likely related to degraded representations of reward values. However, the RL tasks used to date have required active responses to both reward and punishing stimuli. Pavlovian biases have been shown to affect performance on these tasks through invigoration of action to reward and inhibition of action to punishment, and may be partially responsible for the effects found in patients. Forty-five patients with schizophrenia and 30 demographically-matched controls...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/pavlovian-go-no-go-task/" title="pavlovian go/no-go task">pavlovian go/no-go task </a><a class="tag" href="/opendata/tags/schizotypy/" title="schizotypy">schizotypy </a><a class="tag" href="/opendata/tags/m-eeg/" title="m/eeg">m/eeg </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/gillan-et-al-2016/">Gillan et al. (2016)</a></h3></div><div class="post-subtitle"><h4>Characterizing a psychiatric symptom dimension related to deficits in goal-directed control</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.7554/eLife.11305">[Paper] </a><a target="_blank" rel="noopener" href="https://osf.io/usdgt/"> [Data]</a></div><div class="post-content"><p>Prominent theories suggest that compulsive behaviors, characteristic of obsessive-compulsive disorder and addiction, are driven by shared deficits in goal-directed control, which confers vulnerability for developing rigid habits. However, recent studies have shown that deficient goal-directed control accompanies several disorders, including those without an obvious compulsive element. Reasoning that this lack of clinical specificity might reflect broader issues with psychiatric diagnostic categories, we investigated whether a dimensional approach would better delineate...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/schizotypy/" title="schizotypy">schizotypy </a><a class="tag" href="/opendata/tags/anxiety/" title="anxiety">anxiety </a><a class="tag" href="/opendata/tags/depression/" title="depression">depression </a><a class="tag" href="/opendata/tags/compulsivity/" title="compulsivity">compulsivity </a><a class="tag" href="/opendata/tags/two-step/" title="two-step">two-step </a><a class="tag" href="/opendata/tags/impulsivity/" title="impulsivity">impulsivity </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/schobel-et-al-2016/">Schöbel et al. (2016)</a></h3></div><div class="post-subtitle"><h4>Social Influences in Sequential Decision Making</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1371/journal.pone.0146536">[Paper] </a><a target="_blank" rel="noopener" href="http://dx.doi.org/10.6084/m9.figshare.1597662"> [Data]</a></div><div class="post-content"><p>People often make decisions in a social environment. The present work examines social influence on peoples decisions in a sequential decision-making situation. In the first experimental study, we implemented an information cascade paradigm, illustrating that people infer information from decisions of others and use this information to make their own decisions. We followed a cognitive modeling approach to elicit the weight people give to social as compared to private individual information. The proposed social influence model shows that participants overweight their own...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/social-decision-making/" title="social decision making">social decision making </a><a class="tag" href="/opendata/tags/sequential-decision-making/" title="sequential decision making">sequential decision making </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/bach-2015/">Bach (2015)</a></h3></div><div class="post-subtitle"><h4>Anxiety-like behavioural inhibition is normative under environmental threat-reward correlations</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1371/journal.pcbi.1004646">[Paper] </a><a target="_blank" rel="noopener" href="https://datadryad.org/stash/dataset/doi:10.5061/dryad.bd4gs"> [Data]</a></div><div class="post-content"><p>Behavioural inhibition is a key anxiety-like behaviour in rodents and humans, distinct from avoidance of danger, and reduced by anxiolytic drugs. In some situations, it is not clear how behavioural inhibition minimises harm or maximises benefit for the agent, and can even appear counterproductive. Extant explanations of this phenomenon make use of descriptive models but do not provide a formal assessment of its adaptive value. This hampers a better understanding of the neural computations underlying anxiety behaviour. Here, we analyse a standard rodent anxiety model,...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/anxiety/" title="anxiety">anxiety </a><a class="tag" href="/opendata/tags/sequential-decision-making/" title="sequential decision making">sequential decision making </a><a class="tag" href="/opendata/tags/approach-avoidance/" title="approach/avoidance">approach/avoidance </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/kristjansson-et-al-2014/">Kristjansson et al. (2014)</a></h3></div><div class="post-subtitle"><h4>Common attentional constraints in visual foraging</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1371/journal.pone.0100752">[Paper] </a><a target="_blank" rel="noopener" href="https://doi.org/10.1371/journal.pone.0100752"> [Data]</a></div><div class="post-content"><p>Predators are known to select food of the same type in non-random sequences or “runs” that are longer than would be expected by chance. If prey are conspicuous, predators will switch between available sources, interleaving runs of different prey types. However, when prey are cryptic, predators tend to focus on one food type at a time, effectively ignoring equally available sources. This latter finding is regarded as a key indicator that animal foraging is strongly constrained by attention. It is unknown whether human foraging is equally constrained. Here, using a novel...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/martin-et-al-2013/">Martin et al. (2013)</a></h3></div><div class="post-subtitle"><h4>Temporal event structure and timing in schizophrenia: preserved binding in a longer "now"</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1016/j.neuropsychologia.2012.07.002">[Paper] </a><a target="_blank" rel="noopener" href="https://osf.io/3u98c/"> [Data]</a></div><div class="post-content"><p>Patients with schizophrenia experience a loss of temporal continuity or subjective fragmentation along the temporal dimension. Here, we develop the hypothesis that impaired temporal awareness results from a perturbed structuring of events in time-i.e., canonical neural dynamics. To address this, 26 patients and their matched controls took part in two psychophysical studies using desynchronized audiovisual speech. Two tasks were used and compared: first, an identification task testing for multisensory binding impairments in which participants reported what they heard...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/schizotypy/" title="schizotypy">schizotypy </a><a class="tag" href="/opendata/tags/time-perception/" title="time perception">time perception </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/fielder-glockner-2012/">Fielder &amp; Glöckner (2012)</a></h3></div><div class="post-subtitle"><h4>The dynamics of decision making in risky choice: an eye-tracking analysis</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.3389/fpsyg.2012.00335">[Paper] </a><a target="_blank" rel="noopener" href="https://osf.io/kkmbj/"> [Data]</a></div><div class="post-content"><p>In the last years, research on risky choice has moved beyond analyzing choices only. Models have been suggested that aim to describe the underlying cognitive processes and some studies have tested process predictions of these models. Prominent approaches are evidence accumulation models such as decision field theory (DFT), simple serial heuristic models such as the adaptive toolbox, and connectionist approaches such as the parallel constraint satisfaction (PCS) model. In two studies involving measures of attention and pupil dilation, we investigate hypotheses derived...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/eye-tracking/" title="eye-tracking">eye-tracking </a><a class="tag" href="/opendata/tags/risk-sensitivity/" title="risk sensitivity">risk sensitivity </a><a class="tag" href="/opendata/tags/decisions-from-description/" title="decisions from description">decisions from description </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/niv-et-al-2012/">Niv et al. (2012)</a></h3></div><div class="post-subtitle"><h4>Neural prediction errors reveal a risk-sensitive reinforcement learning process in the human brain</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1523/JNEUROSCI.5498-10.2012">[Paper] </a><a target="_blank" rel="noopener" href="https://drive.google.com/file/d/1oHgOYjKdvLM_FMpgpJXa30wqwk_8qaE7/view"> [Data]</a></div><div class="post-content"><p>Humans and animals are exquisitely, though idiosyncratically, sensitive to risk or variance in the outcomes of their actions. Economic, psychological, and neural aspects of this are well studied when information about risk is provided explicitly. However, we must normally learn about outcomes from experience, through trial and error. Traditional models of such reinforcement learning focus on learning about the mean reward value of cues and ignore higher order moments such as variance. We used fMRI to test whether the neural correlates of human reinforcement learning are...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/2-arm-bandit/" title="2-arm bandit">2-arm bandit </a><a class="tag" href="/opendata/tags/risk-sensitivity/" title="risk sensitivity">risk sensitivity </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/opendata/glockner-pachur-2012/">Glockner &amp; Pachur (2012)</a></h3></div><div class="post-subtitle"><h4>Cognitive models of risky choice: Parameter stability and predictive accuracy of prospect theory</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1016/j.cognition.2011.12.002">[Paper] </a><a target="_blank" rel="noopener" href="https://osf.io/7khwj/"> [Data]</a></div><div class="post-content"><p>In the behavioral sciences, a popular approach to describe and predict behavior is cognitive modeling with adjustable parameters (i.e., which can be fitted to data). Modeling with adjustable parameters allows, among other things, measuring differences between people. At the same time, parameter estimation also bears the risk of overfitting. Are individual differences as measured by model parameters stable enough to improve the ability to predict behavior as compared to modeling without adjustable parameters? We examined this issue in cumulative prospect theory (CPT),...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opendata/tags/decisions-from-description/" title="decisions from description">decisions from description </a></div></div></div></div><div class="pagination"><ul class="clearfix"><li class="pre pagbuttons"><a class="btn" role="navigation" href="/opendata/page/15/">Previous</a></li></ul></div></div></div></div><script src="/opendata/js/jquery-migrate-1.2.1.min.js"></script><script src="/opendata/js/jquery.appear.js"></script><script src="/opendata/js/add-bookmark.js"></script><script>(function(window){var INSIGHT_CONFIG={TRANSLATION:{POSTS:"Posts",PAGES:"Pages",CATEGORIES:"Categories",TAGS:"Tags",UNTITLED:"(Untitled)",},CONTENT_URL:"/opendata/content.json",};window.INSIGHT_CONFIG=INSIGHT_CONFIG})(window);</script><script src="/opendata/js/insight.js" defer></script><div class="searchbox ins-search"><div class="searchbox-container ins-search-container"><div class="searchbox-input-wrapper"><input class="searchbox-input ins-search-input" type="text" placeholder="Search..."><span class="searchbox-close"><a class="fa fa-times-circle" onclick="closeWindow();"></a></span></div><div class="searchbox-result-wrapper ins-section-wrapper"><div class="ins-section-container"><p>Seraching...</p></div></div></div></div></body></html>