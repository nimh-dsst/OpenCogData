<!DOCTYPE html><html lang="zh-CN"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta name="author" content="DSST/NIMH"><title>Lehmann et al. (2019) Â· OpenCogData</title><meta name="description" content="In many daily tasks, we make multiple decisions before reaching a goal. In order to learn such sequences of decisions, a mechanism to link earlier act"><meta name="keywords"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="renderer" content="webkit"><link rel="shortcut icon" type="image/x-icon" href="/images/favicon.webp"><link rel="stylesheet" href="/opencogdata/css/style.css"><link rel="stylesheet" href="/opencogdata/css/blog_basic.css"><link rel="stylesheet" href="/opencogdata/css/font-awesome.min.css"><link rel="stylesheet" href="/opencogdata/css/insight.css"><link rel="stylesheet" href="/opencogdata/css/search.css"><link rel="alternate" type="application/atom+xml" title="ATOM 1.0" href="/atom.xml"><script src="/opencogdata/js/jquery.js"></script><!-- Global site tag (gtag.js) - Google Analytics--><script async src="https://www.googletagmanager.com/gtag/js?id=G-PTJE4Z001J"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-PTJE4Z001J');</script><meta name="generator" content="Hexo 6.3.0"></head><body><div class="page-top animated fadeInDown"><div class="nav"><li><a href="/opencogdata">Home</a></li><li><a href="/opencogdata/archives">Archives</a></li><li><a href="/opencogdata/tags">Tags</a></li><li><a href="/opencogdata/about">About</a></li><li><a href="/opencogdata/contribute">Contribute</a></li></div><div class="information"><div class="nav_right_btn"><li><a class="fa fa-chevron-left" onclick="window.history.go(-1)"></a></li><li><a class="fa fa-search" onclick="openWindow();"></a></li></div><div class="avatar"><img src="/opencogdata/images/logo.webp" alt="favicon"></div></div></div><div class="sidebar animated fadeInDown"><div class="sidebar-top"><div class="logo-title"><div class="title"><img src="/opencogdata/images/logo.webp" style="width:175px;" alt="favicon"><h3 title=""><a href="/opencogdata">OpenCogData</a></h3><div class="description"><p>A collection of publicly available<br>cognitve task datasets</p></div></div><ul class="social-links"><li><a target="_blank" rel="noopener" href="https://github.com/nimh-dsst/opencogdata"><i class="fa fa-github"></i></a></li></ul></div></div><div class="footer"><div class="p"> <span> MIT License </span><i class="fa fa-star"></i><span> DSST/NIMH</span></div><div class="by_farbox"><span>Powered by </span><a href="https://hexo.io/zh-cn/" target="_blank">Hexo </a><span> & </span><span>Anatolo </span></div><div class="beian"></div></div></div><div class="main"><div class="autopagerize_page_element"><div class="content"><div class="post-page"><div class="post animated fadeInDown"><div class="post-title"><h3><a>Lehmann et al. (2019)</a></h3></div><div class="post-subtitle"><h4>One-shot learning and behavioral eligibility traces in sequential decision making</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.7554/eLife.47463">[Paper] </a><a target="_blank" rel="noopener" href="https://datadryad.org/stash/dataset/doi:10.5061/dryad.j7h6f69"> [Data]</a></div><div class="post-content"><p><p>In many daily tasks, we make multiple decisions before reaching a goal. In order to learn such sequences of decisions, a mechanism to link earlier actions to later reward is necessary. Reinforcement learning (RL) theory suggests two classes of algorithms solving this credit assignment problem: In classic temporal-difference learning, earlier actions receive reward information only after multiple repetitions of the task, whereas models with eligibility traces reinforce entire sequences of actions from a single experience (one-shot). Here, we show one-shot learning of sequences. We developed a novel paradigm to directly observe which actions and states along a multi-step sequence are reinforced after a single reward. By focusing our analysis on those states for which RL with and without eligibility trace make qualitatively distinct predictions, we find direct behavioral (choice probability) and physiological (pupil dilation) signatures of reinforcement learning with eligibility trace across multiple sensory modalities.</p>
</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/opencogdata/tags/eye-tracking/" title="eye-tracking">eye-tracking </a><a class="tag" href="/opencogdata/tags/sequential-decision-making/" title="sequential decision making">sequential decision making </a></div></div></div></div><div class="pagination"><ul class="clearfix"><li class="pre pagbuttons"><a class="btn" role="navigation" href="/opencogdata/grosskurth-et-al-2019/" title="Grosskurth et al. (2019)">Previous</a></li><li class="next pagbuttons"><a class="btn" role="navigation" href="/opencogdata/beltzer-et-al-2019/" title="Beltzer et al. (2019)">Next</a></li></ul></div><script src="/opencogdata/js/visitors.js"></script></div></div></div></div><script src="/opencogdata/js/jquery-migrate-1.2.1.min.js"></script><script src="/opencogdata/js/jquery.appear.js"></script><script src="/opencogdata/js/add-bookmark.js"></script><script>(function(window){var INSIGHT_CONFIG={TRANSLATION:{POSTS:"Posts",PAGES:"Pages",CATEGORIES:"Categories",TAGS:"Tags",UNTITLED:"(Untitled)",},CONTENT_URL:"/opencogdata/content.json",};window.INSIGHT_CONFIG=INSIGHT_CONFIG})(window);</script><script src="/opencogdata/js/insight.js" defer></script><div class="searchbox ins-search"><div class="searchbox-container ins-search-container"><div class="searchbox-input-wrapper"><input class="searchbox-input ins-search-input" type="text" placeholder="Search..."><span class="searchbox-close"><a class="fa fa-times-circle" onclick="closeWindow();"></a></span></div><div class="searchbox-result-wrapper ins-section-wrapper"><div class="ins-section-container"><p>Seraching...</p></div></div></div></div></body></html>