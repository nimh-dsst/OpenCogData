<!DOCTYPE html><html lang="zh-CN"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta name="author" content="DSST/NIMH"><title>Harris et al. (2022) · OpenCogData</title><meta name="description" content="In this study, we examined the relationship between physiological encoding of surprise and the learning of anticipatory eye movements. Active inferenc"><meta name="keywords"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="renderer" content="webkit"><link rel="shortcut icon" type="image/x-icon" href="/images/favicon.webp"><link rel="stylesheet" href="/opencogdata/css/style.css"><link rel="stylesheet" href="/opencogdata/css/blog_basic.css"><link rel="stylesheet" href="/opencogdata/css/font-awesome.min.css"><link rel="stylesheet" href="/opencogdata/css/insight.css"><link rel="stylesheet" href="/opencogdata/css/search.css"><link rel="alternate" type="application/atom+xml" title="ATOM 1.0" href="/atom.xml"><script src="/opencogdata/js/jquery.js"></script><!-- Global site tag (gtag.js) - Google Analytics--><script async src="https://www.googletagmanager.com/gtag/js?id=G-PTJE4Z001J"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-PTJE4Z001J');</script><meta name="generator" content="Hexo 7.0.0"></head><body><div class="page-top animated fadeInDown"><div class="nav"><li><a href="/opencogdata">Home</a></li><li><a href="/opencogdata/archives">Archives</a></li><li><a href="/opencogdata/tags">Tags</a></li><li><a href="/opencogdata/about">About</a></li><li><a href="/opencogdata/contribute">Contribute</a></li></div><div class="information"><div class="nav_right_btn"><li><a class="fa fa-chevron-left" onclick="window.history.go(-1)"></a></li><li><a class="fa fa-search" onclick="openWindow();"></a></li></div><div class="avatar"><img src="/opencogdata/images/logo.webp" alt="favicon"></div></div></div><div class="sidebar animated fadeInDown"><div class="sidebar-top"><div class="logo-title"><div class="title"><img src="/opencogdata/images/logo.webp" style="width:175px;" alt="favicon"><h3 title=""><a href="/opencogdata">OpenCogData</a></h3><div class="description"><p>A collection of publicly available<br>cognitve task datasets</p></div></div><ul class="social-links"><li><a target="_blank" rel="noopener" href="https://github.com/nimh-dsst/opencogdata"><i class="fa fa-github"></i></a></li></ul></div></div><div class="footer"><div class="p"> <span> MIT License </span><i class="fa fa-star"></i><span> DSST/NIMH</span></div><div class="by_farbox"><span>Powered by </span><a href="https://hexo.io/zh-cn/" target="_blank">Hexo </a><span> & </span><span>Anatolo </span></div><div class="beian"></div></div></div><div class="main"><div class="autopagerize_page_element"><div class="content"><div class="post-page"><div class="post animated fadeInDown"><div class="post-title"><h3><a>Harris et al. (2022)</a></h3></div><div class="post-subtitle"><h4>Task-evoked pupillary responses track precision-weighted prediction errors and learning rate during interceptive visuomotor actions</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1038/s41598-022-26544-w">[Paper] </a><a target="_blank" rel="noopener" href="https://osf.io/z96q8/"> [Data]</a></div><div class="post-content"><p><p>In this study, we examined the relationship between physiological encoding of surprise and the learning of anticipatory eye movements. Active inference portrays perception and action as interconnected inference processes, driven by the imperative to minimise the surprise of sensory observations. To examine this characterisation of oculomotor learning during a hand-eye coordination task, we tested whether anticipatory eye movements were updated in accordance with Bayesian principles and whether trial-by-trial learning rates tracked pupil dilation as a marker of ‘surprise’. Forty-four participants completed an interception task in immersive virtual reality that required them to hit bouncing balls that had either expected or unexpected bounce profiles. We recorded anticipatory eye movements known to index participants’ beliefs about likely ball bounce trajectories. By fitting a hierarchical Bayesian inference model to the trial-wise trajectories of these predictive eye movements, we were able to estimate each individual’s expectations about bounce trajectories, rates of belief updating, and precision-weighted prediction errors. We found that the task-evoked pupil response tracked prediction errors and learning rates but not beliefs about ball bounciness or environmental volatility. These findings are partially consistent with active inference accounts and shed light on how encoding of surprise may shape the control of action.</p>
</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i></div></div></div></div><div class="pagination"><ul class="clearfix"><li class="pre pagbuttons"><a class="btn" role="navigation" href="/opencogdata/pereg-et-al-2022/" title="Pereg et al. (2022)">Previous</a></li><li class="next pagbuttons"><a class="btn" role="navigation" href="/opencogdata/li-et-al-2022/" title="Li et al. (2022)">Next</a></li></ul></div><script src="/opencogdata/js/visitors.js"></script></div></div></div></div><script src="/opencogdata/js/jquery-migrate-1.2.1.min.js"></script><script src="/opencogdata/js/jquery.appear.js"></script><script src="/opencogdata/js/add-bookmark.js"></script><script>(function(window){var INSIGHT_CONFIG={TRANSLATION:{POSTS:"Posts",PAGES:"Pages",CATEGORIES:"Categories",TAGS:"Tags",UNTITLED:"(Untitled)",},CONTENT_URL:"/opencogdata/content.json",};window.INSIGHT_CONFIG=INSIGHT_CONFIG})(window);</script><script src="/opencogdata/js/insight.js" defer></script><div class="searchbox ins-search"><div class="searchbox-container ins-search-container"><div class="searchbox-input-wrapper"><input class="searchbox-input ins-search-input" type="text" placeholder="Search..."><span class="searchbox-close"><a class="fa fa-times-circle" onclick="closeWindow();"></a></span></div><div class="searchbox-result-wrapper ins-section-wrapper"><div class="ins-section-container"><p>Seraching...</p></div></div></div></div></body></html>