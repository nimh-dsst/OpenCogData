<!DOCTYPE html><html lang="zh-CN"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta name="author" content="DSST/NIMH"><title>Locke et al. (2022) Â· OpenCogData</title><meta name="description" content="Perceptual confidence is an important internal signal about the certainty of our decisions and there is a substantial debate on how it is computed. We"><meta name="keywords"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="renderer" content="webkit"><link rel="shortcut icon" type="image/x-icon" href="/images/favicon.webp"><link rel="stylesheet" href="/OpenCogData/css/style.css"><link rel="stylesheet" href="/OpenCogData/css/blog_basic.css"><link rel="stylesheet" href="/OpenCogData/css/font-awesome.min.css"><link rel="stylesheet" href="/OpenCogData/css/insight.css"><link rel="stylesheet" href="/OpenCogData/css/search.css"><link rel="alternate" type="application/atom+xml" title="ATOM 1.0" href="/atom.xml"><script src="/OpenCogData/js/jquery.js"></script><!-- Global site tag (gtag.js) - Google Analytics--><script async src="https://www.googletagmanager.com/gtag/js?id=G-PTJE4Z001J"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-PTJE4Z001J');</script><meta name="generator" content="Hexo 7.1.1"></head><body><div class="page-top animated fadeInDown"><div class="nav"><li><a href="/OpenCogData">Home</a></li><li><a href="/OpenCogData/archives">Archives</a></li><li><a href="/OpenCogData/tags">Tags</a></li><li><a href="/OpenCogData/about">About</a></li><li><a href="/OpenCogData/contribute">Contribute</a></li></div><div class="information"><div class="nav_right_btn"><li><a class="fa fa-chevron-left" onclick="window.history.go(-1)"></a></li><li><a class="fa fa-search" onclick="openWindow();"></a></li></div><div class="avatar"><img src="/OpenCogData/images/logo.webp" alt="favicon"></div></div></div><div class="sidebar animated fadeInDown"><div class="sidebar-top"><div class="logo-title"><div class="title"><img src="/OpenCogData/images/logo.webp" style="width:175px;" alt="favicon"><h3 title=""><a href="/OpenCogData">OpenCogData</a></h3><div class="description"><p>A collection of publicly available<br>cognitve task datasets</p></div></div><ul class="social-links"><li><a target="_blank" rel="noopener" href="https://github.com/nimh-dsst/OpenCogData"><i class="fa fa-github"></i></a></li></ul></div></div><div class="footer"><div class="p"> <span> MIT License </span><i class="fa fa-star"></i><span> DSST/NIMH</span></div><div class="by_farbox"><span>Powered by </span><a href="https://hexo.io/zh-cn/" target="_blank">Hexo </a><span> & </span><span>Anatolo </span></div><div class="beian"></div></div></div><div class="main"><div class="autopagerize_page_element"><div class="content"><div class="post-page"><div class="post animated fadeInDown"><div class="post-title"><h3><a>Locke et al. (2022)</a></h3></div><div class="post-subtitle"><h4>Suprathreshold perceptual decisions constrain models of confidence</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1371/journal.pcbi.1010318">[Paper] </a><a target="_blank" rel="noopener" href="https://osf.io/k2nhq/"> [Data]</a></div><div class="post-content"><p><p>Perceptual confidence is an important internal signal about the certainty of our decisions and there is a substantial debate on how it is computed. We highlight three confidence metric types from the literature: observers either use 1) the full probability distribution to compute probability correct (Probability metrics), 2) point estimates from the perceptual decision process to estimate uncertainty (Evidence-Strength metrics), or 3) heuristic confidence from stimulus-based cues to uncertainty (Heuristic metrics). These metrics are rarely tested against one another, so we examined models of all three types on a suprathreshold spatial discrimination task. Observers were shown a cloud of dots sampled from a dot generating distribution and judged if the mean of the distribution was left or right of centre. In addition to varying the horizontal position of the mean, there were two sensory uncertainty manipulations: the number of dots sampled and the spread of the generating distribution. After every two perceptual decisions, observers made a confidence forced-choice judgement whether they were more confident in the first or second decision. Model results showed that the majority of observers were best-fit by either: 1) the Heuristic model, which used dot cloud position, spread, and number of dots as cues; or 2) an Evidence-Strength model, which computed the distance between the sensory measurement and discrimination criterion, scaled according to sensory uncertainty. An accidental repetition of some sessions also allowed for the measurement of confidence agreement for identical pairs of stimuli. This N-pass analysis revealed that human observers were more consistent than their best-fitting model would predict, indicating there are still aspects of confidence that are not captured by our modelling. As such, we propose confidence agreement as a useful technique for computational studies of confidence. Taken together, these findings highlight the idiosyncratic nature of confidence computations for complex decision contexts and the need to consider different potential metrics and transformations in the confidence computation.</p>
</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i></div></div></div></div><div class="pagination"><ul class="clearfix"><li class="pre pagbuttons"><a class="btn" role="navigation" href="/OpenCogData/jana-aron-2022/" title="Jana &amp; Aron (2022)">Previous</a></li><li class="next pagbuttons"><a class="btn" role="navigation" href="/OpenCogData/molter-et-al-2022/" title="Molter et al. (2022)">Next</a></li></ul></div><script src="/OpenCogData/js/visitors.js"></script></div></div></div></div><script src="/OpenCogData/js/jquery-migrate-1.2.1.min.js"></script><script src="/OpenCogData/js/jquery.appear.js"></script><script src="/OpenCogData/js/add-bookmark.js"></script><script>(function(window){var INSIGHT_CONFIG={TRANSLATION:{POSTS:"Posts",PAGES:"Pages",CATEGORIES:"Categories",TAGS:"Tags",UNTITLED:"(Untitled)",},CONTENT_URL:"/OpenCogData/content.json",};window.INSIGHT_CONFIG=INSIGHT_CONFIG})(window);</script><script src="/OpenCogData/js/insight.js" defer></script><div class="searchbox ins-search"><div class="searchbox-container ins-search-container"><div class="searchbox-input-wrapper"><input class="searchbox-input ins-search-input" type="text" placeholder="Search..."><span class="searchbox-close"><a class="fa fa-times-circle" onclick="closeWindow();"></a></span></div><div class="searchbox-result-wrapper ins-section-wrapper"><div class="ins-section-container"><p>Seraching...</p></div></div></div></div></body></html>