<!DOCTYPE html><html lang="zh-CN"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta name="author" content="DSST/NIMH"><title>Williams et al. (2022) · OpenCogData</title><meta name="description" content="Visual object recognition is not performed in isolation but depends on prior knowledge and context. Here, we found that auditory context plays a criti"><meta name="keywords"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="renderer" content="webkit"><link rel="shortcut icon" type="image/x-icon" href="/images/favicon.webp"><link rel="stylesheet" href="/OpenCogData/css/style.css"><link rel="stylesheet" href="/OpenCogData/css/blog_basic.css"><link rel="stylesheet" href="/OpenCogData/css/font-awesome.min.css"><link rel="stylesheet" href="/OpenCogData/css/insight.css"><link rel="stylesheet" href="/OpenCogData/css/search.css"><link rel="alternate" type="application/atom+xml" title="ATOM 1.0" href="/atom.xml"><script src="/OpenCogData/js/jquery.js"></script><!-- Global site tag (gtag.js) - Google Analytics--><script async src="https://www.googletagmanager.com/gtag/js?id=G-PTJE4Z001J"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-PTJE4Z001J');</script><meta name="generator" content="Hexo 6.3.0"></head><body><div class="page-top animated fadeInDown"><div class="nav"><li><a href="/OpenCogData">Home</a></li><li><a href="/OpenCogData/archives">Archives</a></li><li><a href="/OpenCogData/tags">Tags</a></li><li><a href="/OpenCogData/about">About</a></li><li><a href="/OpenCogData/contribute">Contribute</a></li></div><div class="information"><div class="nav_right_btn"><li><a class="fa fa-chevron-left" onclick="window.history.go(-1)"></a></li><li><a class="fa fa-search" onclick="openWindow();"></a></li></div><div class="avatar"><img src="/OpenCogData/images/logo.webp" alt="favicon"></div></div></div><div class="sidebar animated fadeInDown"><div class="sidebar-top"><div class="logo-title"><div class="title"><img src="/OpenCogData/images/logo.webp" style="width:175px;" alt="favicon"><h3 title=""><a href="/OpenCogData">OpenCogData</a></h3><div class="description"><p>A collection of publicly available<br>cognitve task datasets</p></div></div><ul class="social-links"><li><a target="_blank" rel="noopener" href="https://github.com/nimh-dsst/OpenCogData"><i class="fa fa-github"></i></a></li></ul></div></div><div class="footer"><div class="p"> <span> MIT License </span><i class="fa fa-star"></i><span> DSST/NIMH</span></div><div class="by_farbox"><span>Powered by </span><a href="https://hexo.io/zh-cn/" target="_blank">Hexo </a><span> & </span><span>Anatolo </span></div><div class="beian"></div></div></div><div class="main"><div class="autopagerize_page_element"><div class="content"><div class="post-page"><div class="post animated fadeInDown"><div class="post-title"><h3><a>Williams et al. (2022)</a></h3></div><div class="post-subtitle"><h4>What you see is what you hear: Sounds alter the contents of visual perception</h4></div><div class="post-links"><a target="_blank" rel="noopener" href="https://doi.org/10.1177/09567976221121348">[Paper] </a><a target="_blank" rel="noopener" href="https://osf.io/85kwv"> [Data]</a></div><div class="post-content"><p><p>Visual object recognition is not performed in isolation but depends on prior knowledge and context. Here, we found that auditory context plays a critical role in visual object perception. Using a psychophysical task in which naturalistic sounds were paired with noisy visual inputs, we demonstrated across two experiments (young adults; ns &#x3D; 18-40 in Experiments 1 and 2, respectively) that the representations of ambiguous visual objects were shifted toward the visual features of an object that were related to the incidental sound. In a series of control experiments, we found that these effects were not driven by decision or response biases (ns &#x3D; 40-85) nor were they due to top-down expectations (n &#x3D; 40). Instead, these effects were driven by the continuous integration of audiovisual inputs during perception itself. Together, our results demonstrate that the perceptual experience of visual objects is directly shaped by naturalistic auditory context, which provides independent and diagnostic information about the visual world.</p>
</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-tag"></i><a class="tag" href="/OpenCogData/tags/perceptual-decision-making/" title="perceptual decision making">perceptual decision making </a><a class="tag" href="/OpenCogData/tags/visual-perception/" title="visual perception">visual perception </a><a class="tag" href="/OpenCogData/tags/auditory-perception/" title="auditory perception">auditory perception </a><a class="tag" href="/OpenCogData/tags/multisensory-integration/" title="multisensory integration">multisensory integration </a></div></div></div></div><div class="pagination"><ul class="clearfix"><li class="pre pagbuttons"><a class="btn" role="navigation" href="/OpenCogData/mathar-et-al-2022/" title="Mathar et al. (2022)">Previous</a></li><li class="next pagbuttons"><a class="btn" role="navigation" href="/OpenCogData/elteto-et-al-2022/" title="Éltető et al. (2022)">Next</a></li></ul></div><script src="/OpenCogData/js/visitors.js"></script></div></div></div></div><script src="/OpenCogData/js/jquery-migrate-1.2.1.min.js"></script><script src="/OpenCogData/js/jquery.appear.js"></script><script src="/OpenCogData/js/add-bookmark.js"></script><script>(function(window){var INSIGHT_CONFIG={TRANSLATION:{POSTS:"Posts",PAGES:"Pages",CATEGORIES:"Categories",TAGS:"Tags",UNTITLED:"(Untitled)",},CONTENT_URL:"/OpenCogData/content.json",};window.INSIGHT_CONFIG=INSIGHT_CONFIG})(window);</script><script src="/OpenCogData/js/insight.js" defer></script><div class="searchbox ins-search"><div class="searchbox-container ins-search-container"><div class="searchbox-input-wrapper"><input class="searchbox-input ins-search-input" type="text" placeholder="Search..."><span class="searchbox-close"><a class="fa fa-times-circle" onclick="closeWindow();"></a></span></div><div class="searchbox-result-wrapper ins-section-wrapper"><div class="ins-section-container"><p>Seraching...</p></div></div></div></div></body></html>